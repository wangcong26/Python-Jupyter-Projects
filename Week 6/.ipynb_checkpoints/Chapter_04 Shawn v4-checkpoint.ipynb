{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (40 points) For the Black-Litterman example in the lecture, how unsure do you have to be about the market prior (i.e. what value of s) in order to make the expected return on pounds equal to the expected return on yen? Display the values of the matrix 1/ð‘  ð¶^(âˆ’1)+ð‘‰â€²ð›¤^(âˆ’1) ð‘‰ and the vector 1/ð‘  ð¶^(âˆ’1) ðœ‡_ð¶ð´ð‘ƒð‘€+ð‘‰^â€² ð›¤^(âˆ’1) p that you obtain, along with the new estimated mean return vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fredapi\n",
    "import qrbook_funcs as qf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2138 -0.5389  0.9821] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5194 0.2494 0.2207]\n",
      "C= [0.2494 0.3568 0.1166]     (4.20)\n",
      "   [0.2207 0.1166 0.4155]\n",
      "(%/day)Â² units\n",
      "  \n",
      "From 1971-01-05 to 2018-12-31 ( 12036 observations)\n"
     ]
    }
   ],
   "source": [
    "lastday=qf.LastYearEnd()\n",
    "#Swiss franc, pound sterling, Japanese Yen\n",
    "seriesnames=['DEXSZUS','DEXUSUK','DEXJPUS']\n",
    "cdates,ratematrix=qf.GetFREDMatrix(seriesnames,enddate=lastday)\n",
    "\n",
    "#Convert levels to log-returns\n",
    "#First take logs of the currency levels\n",
    "#Currency exchange rates are usually expressed in the direction\n",
    "#that will make the rate > 1\n",
    "#Swissie and yen are in currency/dollar, but\n",
    "#pounds is in dollar/currency. Reverse signs\n",
    "#so everything is in dollar/currency\n",
    "\n",
    "#Do each currency separately to account for separate missing data patterns\n",
    "#dlgs is a list of lists of length 3 corresponding to the 3 currencies\n",
    "#The value in dlgs is nan if there is missing data for the present or previous day's observation\n",
    "#Otherwise it is the log of today/yesterday\n",
    "multipliers=[-1,1,-1]\n",
    "dlgs=[]\n",
    "for i in range(len(multipliers)):\n",
    "    lgrates=[]\n",
    "    previous=-1\n",
    "    for t in range(len(ratematrix)):\n",
    "        if pd.isna(ratematrix[t][i]) or ratematrix[t][i]<=0:\n",
    "            lgrates.append(np.nan)    #Append a nan\n",
    "        else:\n",
    "            if previous < 0:    #This is the first data point\n",
    "                lgrates.append(np.nan)\n",
    "            else:\n",
    "                lgrates.append(np.log(ratematrix[t][i]/previous)*multipliers[i])\n",
    "            previous=ratematrix[t][i]\n",
    "    dlgs.append(lgrates)\n",
    "\n",
    "#dlgs is the transpose of what we want - flip it\n",
    "dlgs=np.transpose(dlgs)\n",
    "\n",
    "#Delete any time periods that don't have data\n",
    "lgdates=[]\n",
    "difflgs=[]\n",
    "for t in range(len(dlgs)):\n",
    "    if all(pd.notna(dlgs[t])):\n",
    "        #include this time period\n",
    "        difflgs.append(dlgs[t])\n",
    "        lgdates.append(cdates[t])\n",
    "\n",
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(difflgs)\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)\n",
    "\n",
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c[0]*10000)\n",
    "print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",lgdates[0],\"to\",lgdates[-1],\"(\",len(lgdates),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(difflgs)\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2138 -0.5389  0.9821] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5194 0.2494 0.2207]\n",
      "C= [0.2494 0.3568 0.1166]     (4.20)\n",
      "   [0.2207 0.1166 0.4155]\n",
      "(%/day)Â² units\n",
      "  \n",
      "From 1971-01-05 to 2018-12-31 ( 12036 observations)\n"
     ]
    }
   ],
   "source": [
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c[0]*10000)\n",
    "print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",lgdates[0],\"to\",lgdates[-1],\"(\",len(lgdates),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           [ 3.4048 -1.9702 -1.2556]\n",
      "C-inverse= [-1.9702  4.226  -0.1393]     (4.21)\n",
      "           [-1.2556 -0.1393  3.113 ]\n",
      "(days/%)Â² units\n"
     ]
    }
   ],
   "source": [
    "#invert the c matrix, which is in (fraction/day)^2 units\n",
    "#so ci (c-inverse) is in (days/fraction)^2 units\n",
    "ci=np.linalg.inv(c)\n",
    "print(\"          \",ci[0]/10000)\n",
    "#Jupyter doesn't like this superscript\n",
    "#print(f'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}=',ci[1]/10000,\"    (4.21)\")\n",
    "print(f'C-inverse=',ci[1]/10000,\"    (4.21)\")\n",
    "print(\"          \",ci[2]/10000)\n",
    "print(f'(days/%)\\N{SUPERSCRIPT TWO} units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 4.013520703645339 (days/%)Â²\n",
      "u'(C-inverse)m = 0.7639500543759743 days\n",
      "m'(C-inverse)m = 8.977995216452298 bps\n"
     ]
    }
   ],
   "source": [
    "#sum entries in ci\n",
    "uciu=np.sum(ci)\n",
    "\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu/10000,f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "ucim=np.sum(np.matmul(ci,m))\n",
    "print(f'u\\'(C-inverse)m =',ucim,'days')\n",
    "mcim=np.matmul(m,np.matmul(ci,m))\n",
    "print(f'm\\'(C-inverse)m =',mcim*10000,'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w'=lambda [ 3.9275 -5.2086  1.2812] + [0.0446 0.5273 0.4281]     (4.15)#\n",
      "mu=(lambda * 8.832581817923925 )+ 0.19034411699486328  bps/day    (4.18)#\n",
      "sigma=sqrt(lambdaÂ² * 8.832581817923925 + 0.24915780279686497 ) (%/day)   (4.19)#\n"
     ]
    }
   ],
   "source": [
    "#Vectors for equation 4.15\n",
    "u=[1]*3\n",
    "vec2=np.matmul(ci,u)/uciu\n",
    "vec1=np.subtract(np.matmul(ci,m),vec2*ucim)\n",
    "print(f\"w'=lambda\",vec1,\"+\",vec2,\"    (4.15)#\")\n",
    "\n",
    "lambdacoeff=(uciu*mcim-ucim*ucim)/uciu\n",
    "constmu=ucim/uciu\n",
    "print(f'mu=(lambda *',lambdacoeff*10000,\")+\",constmu*10000,\" bps/day    (4.18)#\")\n",
    "print(f'sigma=sqrt(lambda\\N{SUPERSCRIPT TWO} *',lambdacoeff*10000,'+',10000/uciu,') (%/day)   (4.19)#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is Black Littleman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mkt mu= 0.7655167134492344  bps/day\n",
      "Mkt sigmaÂ²= 0.3245879295498583 (%/day)Â²\n"
     ]
    }
   ],
   "source": [
    "#Fake \"market\" for the three currencies\n",
    "wmkt=np.array([.05,.15,.8])\n",
    "mumkt=np.matmul(wmkt,m.T)\n",
    "varmkt=np.matmul(np.matmul(wmkt,c),wmkt.T)\n",
    "print('Mkt mu=',mumkt*10000,' bps/day')\n",
    "print(f'Mkt sigma\\N{SUPERSCRIPT TWO}=',varmkt*10000,f'(%/day)\\N{SUPERSCRIPT TWO}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = [0.7391 0.4906 1.1118]\n",
      "mu-CAPM= [0.5919 0.4265 0.8399]  bps/day\n"
     ]
    }
   ],
   "source": [
    "# risk free rate\n",
    "rfrate=10**(-5)\n",
    "rfvec=[rfrate]*3\n",
    "\n",
    "# compute beta vector\n",
    "betavec=np.matmul(c,wmkt)/varmkt\n",
    "print('beta =',betavec)\n",
    "\n",
    "# compute CAPM return\n",
    "mucapm=np.multiply(10000,rfvec+(mumkt-rfrate)*betavec)\n",
    "print('mu-CAPM=',mucapm,' bps/day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-inverse/s= [[ 34048.1695 -19702.0141 -12556.3028]\n",
      " [-19702.0141  42259.7696  -1393.1939]\n",
      " [-12556.3028  -1393.1939  31130.2896]]\n",
      "V'(Gamma-inverse)V= [[     0.      0.     -0.]\n",
      " [     0.  10000. -10000.]\n",
      " [    -0. -10000.  10000.]]\n",
      "Sum= [[ 34048.1695 -19702.0141 -12556.3028]\n",
      " [-19702.0141  52259.7696 -11393.1939]\n",
      " [-12556.3028 -11393.1939  41130.2896]]\n",
      "Sum inverse (x10000)= [[0.5189 0.2449 0.2263]\n",
      " [0.2449 0.3193 0.1632]\n",
      " [0.2263 0.1632 0.3574]]\n"
     ]
    }
   ],
   "source": [
    "#View that pounds will outperform yen\n",
    "view=np.array([0,1,-1])\n",
    "pview=.00002\n",
    "\n",
    "gamma=np.matrix([.0001])\n",
    "sweight=1\n",
    "\n",
    "#First Black-Litterman matrix calculation\n",
    "print('C-inverse/s=', ci/sweight)\n",
    "\n",
    "#Second matrix\n",
    "v1=np.matmul(np.matrix(view).T,np.linalg.inv(gamma))\n",
    "vgvmtrx=np.matmul(v1,np.matrix(view))\n",
    "print('V\\'(Gamma-inverse)V=',vgvmtrx)\n",
    "\n",
    "#Sum of the two\n",
    "print('Sum=',ci/sweight+vgvmtrx)\n",
    "\n",
    "m1inv=np.linalg.inv(ci/sweight+vgvmtrx)\n",
    "print('Sum inverse (x10000)=',m1inv*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-inverse*muCAPM/s= [0.1204 0.5192 1.8121]\n",
      "V'(Gamma-Inverse)p= [[ 0. ]\n",
      " [ 0.2]\n",
      " [-0.2]]\n",
      "Sum= [[0.1204 0.7192 1.6121]]\n"
     ]
    }
   ],
   "source": [
    "cimcs=np.matmul(ci,mucapm/sweight)*10**(-4)\n",
    "print('C-inverse*muCAPM/s=',cimcs)\n",
    "\n",
    "print('V\\'(Gamma-Inverse)p=',v1*pview)\n",
    "m2=cimcs+v1.T*pview\n",
    "print('Sum=',m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Litterman mu: [[0.6034]\n",
      " [0.5222]\n",
      " [0.7208]]\n"
     ]
    }
   ],
   "source": [
    "mufinal=np.matmul(m1inv,m2.T)*10000\n",
    "print('Black-Litterman mu:',mufinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "# part1=np.linalg.inv(sweight*c)\n",
    "# part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "# part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part1+part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firstTerm=np.linalg.inv(part1+part2)*10000\n",
    "# firstTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "# part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "# part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "# part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "# part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secondTerm=(part3*10**(-4)+part4)\n",
    "# secondTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.matmul(firstTerm,secondTerm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to compute the Black Littleman mu\n",
    "def computeBL(s, C, linkArray, gamma, mucapm, pview):\n",
    "    \n",
    "    part1=np.linalg.inv(s*C)\n",
    "    part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "    firstTerm=np.linalg.inv(part1+part2)*10000\n",
    "    \n",
    "    part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "    part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "    secondTerm=(part3*10**(-4)+part4)\n",
    "    \n",
    "    res=np.matmul(firstTerm,secondTerm)\n",
    "       \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.6034],\n",
       "        [0.5222],\n",
       "        [0.7208]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myBL=computeBL(sweight, c, view, gamma, mucapm, pview)\n",
    "myBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our cost function to minimize the difference of GBP and Yen return\n",
    "def computeBLDiff(s):\n",
    "    \n",
    "    part1=np.linalg.inv(s*c)\n",
    "    part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "    firstTerm=np.linalg.inv(part1+part2)*10000\n",
    "    #print(firstTerm)\n",
    "    \n",
    "    part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "    part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "    secondTerm=(part3*10**(-4)+part4)\n",
    "    #print(secondTerm)\n",
    "    \n",
    "    muBL=np.matmul(firstTerm,secondTerm)\n",
    "    \n",
    "    diff_GBP_Yen=abs(muBL.item(1)-muBL.item(2))\n",
    "    return diff_GBP_Yen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1985687052673859"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeBLDiff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 34\n",
      "         Function evaluations: 68\n"
     ]
    }
   ],
   "source": [
    "# minize the difference between GBP and Yen\n",
    "from scipy.optimize import minimize\n",
    "x0 = 1\n",
    "res = minimize(computeBLDiff, x0, method='nelder-mead', options={'xtol': 1e-8, 'disp': True, 'maxiter': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[3.8346],\n",
       "       [3.8346]]), array([7.9140e-11, 1.3038e-10]))\n",
       "           fun: 7.91401388866575e-11\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 68\n",
       "           nit: 34\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([3.8346])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.614 ],\n",
       "        [0.6107],\n",
       "        [0.6107]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeBL(3.8346, c, view, gamma, mucapm, pview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the first term\n",
    "part1=np.linalg.inv(3.8346*c)\n",
    "part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "firstTerm=np.linalg.inv(part1+part2)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the second term\n",
    "part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "secondTerm=(part3*10**(-4)+part4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ð‘  ð¶^(âˆ’1)+ð‘‰â€²ð›¤^(âˆ’1) ð‘‰ \n",
    "\n",
    "Please see result below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.019 , 0.9362, 0.9002],\n",
       "        [0.9362, 1.1007, 0.8011],\n",
       "        [0.9002, 0.8011, 1.1774]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ð‘  ð¶^(âˆ’1) ðœ‡_ð¶ð´ð‘ƒð‘€+ð‘‰^â€² ð›¤^(âˆ’1) p \n",
    "\n",
    "Please see result below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.0299],\n",
       "        [0.335 ],\n",
       "        [0.2666]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Using the franc-yen-pound data from 1971 through the end of 2017, form the covariance matrix. Find the minimum variance portfolio w1. Use Ledoit-Wolf shrinkage (with s=1/3) on this matrix, and find the minimum variance portfolio w2 based on the shrunk matrix. During 2018, which of these portfolios had the smaller variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2476 -0.5009  0.98  ] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5276 0.2528 0.2239]\n",
      "C= [0.2528 0.3592 0.1183]     (4.20)\n",
      "   [0.2239 0.1183 0.4209]\n",
      "(%/day)Â² units\n",
      "  \n",
      "From 1971-01-05 to 2017-12-29 ( 11787 observations)\n"
     ]
    }
   ],
   "source": [
    "lastday='2017-12-29'\n",
    "#Swiss franc, pound sterling, Japanese Yen\n",
    "seriesnames=['DEXSZUS','DEXUSUK','DEXJPUS']\n",
    "cdates,ratematrix=qf.GetFREDMatrix(seriesnames,enddate=lastday)\n",
    "\n",
    "#Convert levels to log-returns\n",
    "#First take logs of the currency levels\n",
    "#Currency exchange rates are usually expressed in the direction\n",
    "#that will make the rate > 1\n",
    "#Swissie and yen are in currency/dollar, but\n",
    "#pounds is in dollar/currency. Reverse signs\n",
    "#so everything is in dollar/currency\n",
    "\n",
    "#Do each currency separately to account for separate missing data patterns\n",
    "#dlgs is a list of lists of length 3 corresponding to the 3 currencies\n",
    "#The value in dlgs is nan if there is missing data for the present or previous day's observation\n",
    "#Otherwise it is the log of today/yesterday\n",
    "multipliers=[-1,1,-1]\n",
    "dlgs=[]\n",
    "for i in range(len(multipliers)):\n",
    "    lgrates=[]\n",
    "    previous=-1\n",
    "    for t in range(len(ratematrix)):\n",
    "        if pd.isna(ratematrix[t][i]) or ratematrix[t][i]<=0:\n",
    "            lgrates.append(np.nan)    #Append a nan\n",
    "        else:\n",
    "            if previous < 0:    #This is the first data point\n",
    "                lgrates.append(np.nan)\n",
    "            else:\n",
    "                lgrates.append(np.log(ratematrix[t][i]/previous)*multipliers[i])\n",
    "            previous=ratematrix[t][i]\n",
    "    dlgs.append(lgrates)\n",
    "\n",
    "#dlgs is the transpose of what we want - flip it\n",
    "dlgs=np.transpose(dlgs)\n",
    "\n",
    "#Delete any time periods that don't have data\n",
    "lgdates=[]\n",
    "difflgs=[]\n",
    "for t in range(len(dlgs)):\n",
    "    if all(pd.notna(dlgs[t])):\n",
    "        #include this time period\n",
    "        difflgs.append(dlgs[t])\n",
    "        lgdates.append(cdates[t])\n",
    "\n",
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(difflgs)\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)\n",
    "\n",
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c[0]*10000)\n",
    "print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",lgdates[0],\"to\",lgdates[-1],\"(\",len(lgdates),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(difflgs)\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2476 -0.5009  0.98  ] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5276 0.2528 0.2239]\n",
      "C= [0.2528 0.3592 0.1183]     (4.20)\n",
      "   [0.2239 0.1183 0.4209]\n",
      "(%/day)Â² units\n",
      "  \n",
      "From 1971-01-05 to 2017-12-29 ( 11787 observations)\n"
     ]
    }
   ],
   "source": [
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c[0]*10000)\n",
    "print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",lgdates[0],\"to\",lgdates[-1],\"(\",len(lgdates),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           [ 3.3573 -1.9558 -1.2362]\n",
      "C-inverse= [-1.9558  4.2067 -0.1417]     (4.21)\n",
      "           [-1.2362 -0.1417  3.0732]\n",
      "(days/%)Â² units\n"
     ]
    }
   ],
   "source": [
    "# compute inverse of C\n",
    "ci=np.linalg.inv(c)\n",
    "print(\"          \",ci[0]/10000)\n",
    "#Jupyter doesn't like this superscript\n",
    "#print(f'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}=',ci[1]/10000,\"    (4.21)\")\n",
    "print(f'C-inverse=',ci[1]/10000,\"    (4.21)\")\n",
    "print(\"          \",ci[2]/10000)\n",
    "print(f'(days/%)\\N{SUPERSCRIPT TWO} units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 3.969846337167373 (days/%)Â²\n",
      "u'(C-inverse)m = 0.8111878199656062 days\n",
      "m'(C-inverse)m = 8.79299851331195 bps\n"
     ]
    }
   ],
   "source": [
    "#sum entries in ci\n",
    "uciu=np.sum(ci)\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "\n",
    "ucim=np.sum(np.matmul(ci,m))\n",
    "print(f'u\\'(C-inverse)m =',ucim, 'days')\n",
    "mcim=np.matmul(m,np.matmul(ci,m))\n",
    "print(f'm\\'(C-inverse)m =',mcim*10000,'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weight for the minimum variance portfolio\n",
    "u_vec=[1]*3\n",
    "w_optimal2017=(np.matmul(ci,u_vec))/uciu\n",
    "\n",
    "# compute the minimum variance\n",
    "variance_minimize=1/uciu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.0416, 0.5313, 0.427 ]), 2.5189891876609403e-05)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the optimal weight w1 and variance of the portfolio for 1971 to 2017\n",
    "w_optimal2017, variance_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute LedoitWolf estimate using 1971 to 2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use directly the given s=1/3\n",
    "s_wolf=1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the three-currency correlation matrix \n",
    "\n",
    "# dimension is 3\n",
    "prev_dim=3\n",
    "\n",
    "# compute S-sample standard deviation on the diagonal and zero elsewhere\n",
    "prev_sig=np.sqrt(np.diag(np.diag(c)))\n",
    "\n",
    "# compute the inverse of S\n",
    "prev_sig_inverse=np.linalg.inv(prev_sig)\n",
    "\n",
    "# compute R=inverse(S)*C*inverse(S)\n",
    "prev_r_matrix=np.matmul(np.matmul(prev_sig_inverse,c),prev_sig_inverse)\n",
    "\n",
    "# Get average correlation (off-diagonal)\n",
    "prev_avg_corr=(np.sum(prev_r_matrix)-prev_dim)/(prev_dim**2-prev_dim)\n",
    "\n",
    "# Centralized prior: (I+Ï(Jâˆ’I)), where Ï is the average off-diagnal correlation, or J*Ï+I*(1-Ï)\n",
    "prev_prior=(np.ones((prev_dim,prev_dim))*prev_avg_corr+np.identity(prev_dim)*(1-prev_avg_corr))\n",
    "\n",
    "# Compute C_rho, S(I+Ï*(Jâˆ’I))S\n",
    "c_rho=np.matmul(np.matmul(prev_sig,prev_prior),prev_sig)\n",
    "\n",
    "# compute Ledoit-Wolf constant-correlation covariance shrinkage estimator\n",
    "ledoit_wolf_est = np.multiply(1-s_wolf,c) + np.multiply(s_wolf, c_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5276, 0.2343, 0.2205],\n",
       "       [0.2343, 0.3592, 0.1376],\n",
       "       [0.2205, 0.1376, 0.4209]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ledoit_wolf_est*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 3.969846337167373 (days/%)Â²\n",
      "u'(C-inverse)m = 0.8111878199656062 days\n",
      "m'(C-inverse)m = 8.79299851331195 bps\n"
     ]
    }
   ],
   "source": [
    "# inverse\n",
    "ci_wolf=np.linalg.inv(ledoit_wolf_est)\n",
    "\n",
    "#sum entries in ci\n",
    "uciu_wolf=np.sum(ci_wolf)\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "\n",
    "ucim_wolf=np.sum(np.matmul(ci_wolf,m))\n",
    "print(f'u\\'(C-inverse)m =',ucim, 'days')\n",
    "mcim_wolf=np.matmul(m,np.matmul(ci_wolf,m))\n",
    "print(f'm\\'(C-inverse)m =',mcim*10000,'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weight using Ledoit-Wolf estimate\n",
    "u_vec=[1]*3\n",
    "w_optimal_wolf_2017=(np.matmul(ci_wolf,u_vec))/uciu_wolf\n",
    "\n",
    "# compute the minimum variance\n",
    "variance_minimize_wolf=1/uciu_wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1013, 0.5014, 0.3972]), 2.5853482413607367e-05)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the optimal weight w2 and variance of the portfolio using ledoit wolf estimate for 1971 to 2017\n",
    "w_optimal_wolf_2017, variance_minimize_wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 2018 data to compute minimum variance portfolio using w1 and w2 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdates2018, ratematrix2018 = qf.GetFREDMatrix(seriesnames, startdate='2018-01-01', enddate='2018-12-31')\n",
    "\n",
    "nobs, t = len(cdates2018), 0\n",
    "while t < nobs:\n",
    "    if all(np.isnan(ratematrix2018[t])):\n",
    "        del ratematrix2018[t]\n",
    "        del cdates2018[t]\n",
    "        nobs -= 1\n",
    "    else:\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018 = pd.DataFrame(ratematrix2018, index =cdates2018, columns = seriesnames)\n",
    "data2018 = data2018.set_index(pd.DatetimeIndex(data2018.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018['DEXSZUS']=data2018['DEXSZUS'].apply(lambda x: 1/x)\n",
    "data2018['DEXJPUS']=data2018['DEXJPUS'].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>DEXJPUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>1.029018</td>\n",
       "      <td>1.3596</td>\n",
       "      <td>0.008914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>1.024380</td>\n",
       "      <td>1.3522</td>\n",
       "      <td>0.008906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>1.025326</td>\n",
       "      <td>1.3539</td>\n",
       "      <td>0.008867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>1.025431</td>\n",
       "      <td>1.3562</td>\n",
       "      <td>0.008835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>1.024380</td>\n",
       "      <td>1.3566</td>\n",
       "      <td>0.008843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DEXSZUS  DEXUSUK   DEXJPUS\n",
       "2018-01-02  1.029018   1.3596  0.008914\n",
       "2018-01-03  1.024380   1.3522  0.008906\n",
       "2018-01-04  1.025326   1.3539  0.008867\n",
       "2018-01-05  1.025431   1.3562  0.008835\n",
       "2018-01-08  1.024380   1.3566  0.008843"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute log to all the values in the dataset\n",
    "data2018=data2018.apply(lambda x: np.log(x))\n",
    "# data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the first difference and drop NA\n",
    "data2018_final=data2018.diff()\n",
    "data2018_final.dropna(inplace=True)\n",
    "#data2018_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length\n",
    "#len(data2018_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d2018=np.array(data2018_final[seriesnames])\n",
    "m2018=np.mean(d2018,axis=0)\n",
    "c2018=np.cov(d2018.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [-0.4703 -2.5494  0.9014] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.1338 0.0892 0.0688]\n",
      "C= [0.0892 0.2402 0.0361]     (4.20)\n",
      "   [0.0688 0.0361 0.1579]\n",
      "(%/day)Â² units\n",
      "  \n",
      "From 2018-01-03 00:00:00 to 2018-12-31 00:00:00 ( 248 observations)\n"
     ]
    }
   ],
   "source": [
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m2018*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c2018[0]*10000)\n",
    "print(\"C=\",c2018[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c2018[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",data2018_final.index[0],\"to\",data2018_final.index[-1],\"(\",len(data2018_final),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance using w1 of 1971-2017 data for 2018 covariance is:  1.1962262246332568e-05\n"
     ]
    }
   ],
   "source": [
    "# Now we use the optimal weight w1 of 1971-2017 to compute the minimum variance for 2018\n",
    "var1_2018=np.matmul(np.matmul(np.transpose(w_optimal2017),c2018),w_optimal2017)\n",
    "print('Variance using w1 of 1971-2017 data for 2018 covariance is: ',var1_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance using w2 of 1971-2017 data for 2018 covariance is:  1.1567748887645887e-05\n"
     ]
    }
   ],
   "source": [
    "# Now we use the optimal weight w2 of 1971-2017 to compute the minimum variance for 2018\n",
    "var2_2018=np.matmul(np.matmul(np.transpose(w_optimal_wolf_2017),c2018),w_optimal_wolf_2017)\n",
    "print('Variance using w2 of 1971-2017 data for 2018 covariance is: ',var2_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "For the 2018 data, we can see that the portfolio with w2 using the wolf shrunk matrix has lower variance than the one with w1. In other words, the shrunk covariance matrix serves as a better estimate than the one using the historical covariance when we estimating the 2018 portfolio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
