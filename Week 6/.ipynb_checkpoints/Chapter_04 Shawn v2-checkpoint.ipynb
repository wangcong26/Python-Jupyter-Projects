{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (40 points) For the Black-Litterman example in the lecture, how unsure do you have to be about the market prior (i.e. what value of s) in order to make the expected return on pounds equal to the expected return on yen? Display the values of the matrix 1/𝑠 𝐶^(−1)+𝑉′𝛤^(−1) 𝑉 and the vector 1/𝑠 𝐶^(−1) 𝜇_𝐶𝐴𝑃𝑀+𝑉^′ 𝛤^(−1) p that you obtain, along with the new estimated mean return vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fredapi\n",
    "import qrbook_funcs as qf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2138 -0.5389  0.9821] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5194 0.2494 0.2207]\n",
      "C= [0.2494 0.3568 0.1166]     (4.20)\n",
      "   [0.2207 0.1166 0.4155]\n",
      "(%/day)² units\n",
      "  \n",
      "From 1971-01-05 to 2018-12-31 ( 12036 observations)\n"
     ]
    }
   ],
   "source": [
    "lastday=qf.LastYearEnd()\n",
    "#Swiss franc, pound sterling, Japanese Yen\n",
    "seriesnames=['DEXSZUS','DEXUSUK','DEXJPUS']\n",
    "cdates,ratematrix=qf.GetFREDMatrix(seriesnames,enddate=lastday)\n",
    "\n",
    "#Convert levels to log-returns\n",
    "#First take logs of the currency levels\n",
    "#Currency exchange rates are usually expressed in the direction\n",
    "#that will make the rate > 1\n",
    "#Swissie and yen are in currency/dollar, but\n",
    "#pounds is in dollar/currency. Reverse signs\n",
    "#so everything is in dollar/currency\n",
    "\n",
    "#Do each currency separately to account for separate missing data patterns\n",
    "#dlgs is a list of lists of length 3 corresponding to the 3 currencies\n",
    "#The value in dlgs is nan if there is missing data for the present or previous day's observation\n",
    "#Otherwise it is the log of today/yesterday\n",
    "multipliers=[-1,1,-1]\n",
    "dlgs=[]\n",
    "for i in range(len(multipliers)):\n",
    "    lgrates=[]\n",
    "    previous=-1\n",
    "    for t in range(len(ratematrix)):\n",
    "        if pd.isna(ratematrix[t][i]) or ratematrix[t][i]<=0:\n",
    "            lgrates.append(np.nan)    #Append a nan\n",
    "        else:\n",
    "            if previous < 0:    #This is the first data point\n",
    "                lgrates.append(np.nan)\n",
    "            else:\n",
    "                lgrates.append(np.log(ratematrix[t][i]/previous)*multipliers[i])\n",
    "            previous=ratematrix[t][i]\n",
    "    dlgs.append(lgrates)\n",
    "\n",
    "#dlgs is the transpose of what we want - flip it\n",
    "dlgs=np.transpose(dlgs)\n",
    "\n",
    "#Delete any time periods that don't have data\n",
    "lgdates=[]\n",
    "difflgs=[]\n",
    "for t in range(len(dlgs)):\n",
    "    if all(pd.notna(dlgs[t])):\n",
    "        #include this time period\n",
    "        difflgs.append(dlgs[t])\n",
    "        lgdates.append(cdates[t])\n",
    "\n",
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(difflgs)\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)\n",
    "\n",
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c[0]*10000)\n",
    "print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",lgdates[0],\"to\",lgdates[-1],\"(\",len(lgdates),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(difflgs)\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2138 -0.5389  0.9821] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5194 0.2494 0.2207]\n",
      "C= [0.2494 0.3568 0.1166]     (4.20)\n",
      "   [0.2207 0.1166 0.4155]\n",
      "(%/day)² units\n",
      "  \n",
      "From 1971-01-05 to 2018-12-31 ( 12036 observations)\n"
     ]
    }
   ],
   "source": [
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c[0]*10000)\n",
    "print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",lgdates[0],\"to\",lgdates[-1],\"(\",len(lgdates),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           [ 3.4048 -1.9702 -1.2556]\n",
      "C-inverse= [-1.9702  4.226  -0.1393]     (4.21)\n",
      "           [-1.2556 -0.1393  3.113 ]\n",
      "(days/%)² units\n"
     ]
    }
   ],
   "source": [
    "#invert the c matrix, which is in (fraction/day)^2 units\n",
    "#so ci (c-inverse) is in (days/fraction)^2 units\n",
    "ci=np.linalg.inv(c)\n",
    "print(\"          \",ci[0]/10000)\n",
    "#Jupyter doesn't like this superscript\n",
    "#print(f'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}=',ci[1]/10000,\"    (4.21)\")\n",
    "print(f'C-inverse=',ci[1]/10000,\"    (4.21)\")\n",
    "print(\"          \",ci[2]/10000)\n",
    "print(f'(days/%)\\N{SUPERSCRIPT TWO} units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 4.013520703645339 (days/%)²\n",
      "u'(C-inverse)m = 0.7639500543759743 days\n",
      "m'(C-inverse)m = 8.977995216452298 bps\n"
     ]
    }
   ],
   "source": [
    "#sum entries in ci\n",
    "uciu=np.sum(ci)\n",
    "\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu/10000,f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "ucim=np.sum(np.matmul(ci,m))\n",
    "print(f'u\\'(C-inverse)m =',ucim,'days')\n",
    "mcim=np.matmul(m,np.matmul(ci,m))\n",
    "print(f'm\\'(C-inverse)m =',mcim*10000,'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w'=lambda [ 3.9275 -5.2086  1.2812] + [0.0446 0.5273 0.4281]     (4.15)#\n",
      "mu=(lambda * 8.832581817923925 )+ 0.19034411699486328  bps/day    (4.18)#\n",
      "sigma=sqrt(lambda² * 8.832581817923925 + 0.24915780279686497 ) (%/day)   (4.19)#\n"
     ]
    }
   ],
   "source": [
    "#Vectors for equation 4.15\n",
    "u=[1]*3\n",
    "vec2=np.matmul(ci,u)/uciu\n",
    "vec1=np.subtract(np.matmul(ci,m),vec2*ucim)\n",
    "print(f\"w'=lambda\",vec1,\"+\",vec2,\"    (4.15)#\")\n",
    "\n",
    "lambdacoeff=(uciu*mcim-ucim*ucim)/uciu\n",
    "constmu=ucim/uciu\n",
    "print(f'mu=(lambda *',lambdacoeff*10000,\")+\",constmu*10000,\" bps/day    (4.18)#\")\n",
    "print(f'sigma=sqrt(lambda\\N{SUPERSCRIPT TWO} *',lambdacoeff*10000,'+',10000/uciu,') (%/day)   (4.19)#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is Black Littleman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mkt mu= 0.7655167134492344  bps/day\n",
      "Mkt sigma²= 0.3245879295498583 (%/day)²\n"
     ]
    }
   ],
   "source": [
    "#Fake \"market\" for the three currencies\n",
    "wmkt=np.array([.05,.15,.8])\n",
    "mumkt=np.matmul(wmkt,m.T)\n",
    "varmkt=np.matmul(np.matmul(wmkt,c),wmkt.T)\n",
    "print('Mkt mu=',mumkt*10000,' bps/day')\n",
    "print(f'Mkt sigma\\N{SUPERSCRIPT TWO}=',varmkt*10000,f'(%/day)\\N{SUPERSCRIPT TWO}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = [0.7391 0.4906 1.1118]\n",
      "mu-CAPM= [0.5919 0.4265 0.8399]  bps/day\n"
     ]
    }
   ],
   "source": [
    "# risk free rate\n",
    "rfrate=10**(-5)\n",
    "rfvec=[rfrate]*3\n",
    "\n",
    "# compute beta vector\n",
    "betavec=np.matmul(c,wmkt)/varmkt\n",
    "print('beta =',betavec)\n",
    "\n",
    "# compute CAPM return\n",
    "mucapm=np.multiply(10000,rfvec+(mumkt-rfrate)*betavec)\n",
    "print('mu-CAPM=',mucapm,' bps/day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-inverse/s= [[ 34048.1695 -19702.0141 -12556.3028]\n",
      " [-19702.0141  42259.7696  -1393.1939]\n",
      " [-12556.3028  -1393.1939  31130.2896]]\n",
      "V'(Gamma-inverse)V= [[     0.      0.     -0.]\n",
      " [     0.  10000. -10000.]\n",
      " [    -0. -10000.  10000.]]\n",
      "Sum= [[ 34048.1695 -19702.0141 -12556.3028]\n",
      " [-19702.0141  52259.7696 -11393.1939]\n",
      " [-12556.3028 -11393.1939  41130.2896]]\n",
      "Sum inverse (x10000)= [[0.5189 0.2449 0.2263]\n",
      " [0.2449 0.3193 0.1632]\n",
      " [0.2263 0.1632 0.3574]]\n"
     ]
    }
   ],
   "source": [
    "#View that pounds will outperform yen\n",
    "view=np.array([0,1,-1])\n",
    "pview=.00002\n",
    "\n",
    "gamma=np.matrix([.0001])\n",
    "sweight=1\n",
    "\n",
    "#First Black-Litterman matrix calculation\n",
    "print('C-inverse/s=', ci/sweight)\n",
    "\n",
    "#Second matrix\n",
    "v1=np.matmul(np.matrix(view).T,np.linalg.inv(gamma))\n",
    "vgvmtrx=np.matmul(v1,np.matrix(view))\n",
    "print('V\\'(Gamma-inverse)V=',vgvmtrx)\n",
    "\n",
    "#Sum of the two\n",
    "print('Sum=',ci/sweight+vgvmtrx)\n",
    "\n",
    "m1inv=np.linalg.inv(ci/sweight+vgvmtrx)\n",
    "print('Sum inverse (x10000)=',m1inv*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-inverse*muCAPM/s= [0.1204 0.5192 1.8121]\n",
      "V'(Gamma-Inverse)p= [[ 0. ]\n",
      " [ 0.2]\n",
      " [-0.2]]\n",
      "Sum= [[0.1204 0.7192 1.6121]]\n"
     ]
    }
   ],
   "source": [
    "cimcs=np.matmul(ci,mucapm/sweight)*10**(-4)\n",
    "print('C-inverse*muCAPM/s=',cimcs)\n",
    "\n",
    "print('V\\'(Gamma-Inverse)p=',v1*pview)\n",
    "m2=cimcs+v1.T*pview\n",
    "print('Sum=',m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Litterman mu: [[0.6034]\n",
      " [0.5222]\n",
      " [0.7208]]\n"
     ]
    }
   ],
   "source": [
    "mufinal=np.matmul(m1inv,m2.T)*10000\n",
    "print('Black-Litterman mu:',mufinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34048.1695, -19702.0141, -12556.3028],\n",
       "       [-19702.0141,  42259.7696,  -1393.1939],\n",
       "       [-12556.3028,  -1393.1939,  31130.2896]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "part1=np.linalg.inv(sweight*c)\n",
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[     0.,      0.,     -0.],\n",
       "        [     0.,  10000., -10000.],\n",
       "        [    -0., -10000.,  10000.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 34048.1695, -19702.0141, -12556.3028],\n",
       "        [-19702.0141,  52259.7696, -11393.1939],\n",
       "        [-12556.3028, -11393.1939,  41130.2896]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1+part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5189, 0.2449, 0.2263],\n",
       "        [0.2449, 0.3193, 0.1632],\n",
       "        [0.2263, 0.1632, 0.3574]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstTerm=np.linalg.inv(part1+part2)*10000\n",
    "firstTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1204.1569],\n",
       "        [ 5191.9712],\n",
       "        [18120.8264]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0. ],\n",
       "        [ 0.2],\n",
       "        [-0.2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.1204],\n",
       "        [0.7192],\n",
       "        [1.6121]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondTerm=(part3*10**(-4)+part4)\n",
    "secondTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.6034],\n",
       "        [0.5222],\n",
       "        [0.7208]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(firstTerm,secondTerm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to compute the Black Littleman mu\n",
    "def computeBL(s, C, linkArray, gamma, mucapm, pview):\n",
    "    \n",
    "    part1=np.linalg.inv(s*C)\n",
    "    part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "    firstTerm=np.linalg.inv(part1+part2)*10000\n",
    "    \n",
    "    part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "    part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "    secondTerm=(part3*10**(-4)+part4)\n",
    "    \n",
    "    res=np.matmul(firstTerm,secondTerm)\n",
    "       \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.6034],\n",
       "        [0.5222],\n",
       "        [0.7208]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myBL=computeBL(sweight, c, view, gamma, mucapm, pview)\n",
    "myBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our cost function to minimize the difference of GBP and Yen return\n",
    "def computeBLDiff(s):\n",
    "    \n",
    "    part1=np.linalg.inv(s*c)\n",
    "    part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "    firstTerm=np.linalg.inv(part1+part2)*10000\n",
    "    #print(firstTerm)\n",
    "    \n",
    "    part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "    part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "    secondTerm=(part3*10**(-4)+part4)\n",
    "    #print(secondTerm)\n",
    "    \n",
    "    muBL=np.matmul(firstTerm,secondTerm)\n",
    "    \n",
    "    diff_GBP_Yen=abs(muBL.item(1)-muBL.item(2))\n",
    "    return diff_GBP_Yen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1985687052673859"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeBLDiff(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 34\n",
      "         Function evaluations: 68\n"
     ]
    }
   ],
   "source": [
    "# minize the difference between GBP and Yen\n",
    "from scipy.optimize import minimize\n",
    "x0 = 1\n",
    "res = minimize(computeBLDiff, x0, method='nelder-mead', options={'xtol': 1e-8, 'disp': True, 'maxiter': 1000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[3.8346],\n",
       "       [3.8346]]), array([7.9140e-11, 1.3038e-10]))\n",
       "           fun: 7.91401388866575e-11\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 68\n",
       "           nit: 34\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([3.8346])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.614 ],\n",
       "        [0.6107],\n",
       "        [0.6107]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeBL(3.8346, c, view, gamma, mucapm, pview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the first term\n",
    "part1=np.linalg.inv(4.4108*c)\n",
    "part2=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(view))\n",
    "firstTerm=np.linalg.inv(part1+part2)*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the second term\n",
    "part3=np.matmul(part1,np.matrix(mucapm).T)\n",
    "part4=np.matmul(np.matmul(np.matrix(view).T,np.linalg.inv(gamma)),np.matrix(pview))\n",
    "secondTerm=(part3*10**(-4)+part4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/𝑠 𝐶^(−1)+𝑉′𝛤^(−1) 𝑉 \n",
    "\n",
    "Please see result below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.2863, 1.0604, 1.0228],\n",
       "        [1.0604, 1.2413, 0.9277],\n",
       "        [1.0228, 0.9277, 1.318 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/𝑠 𝐶^(−1) 𝜇_𝐶𝐴𝑃𝑀+𝑉^′ 𝛤^(−1) p \n",
    "\n",
    "Please see result below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.0273],\n",
       "        [0.3177],\n",
       "        [0.2108]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondTerm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Using the franc-yen-pound data from 1971 through the end of 2017, form the covariance matrix. Find the minimum variance portfolio w1. Use Ledoit-Wolf shrinkage (with s=1/3) on this matrix, and find the minimum variance portfolio w2 based on the shrunk matrix. During 2018, which of these portfolios had the smaller variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set last day of the data\n",
    "lastday2017='2017-12-29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data for Swiss franc, pound sterling, Japanese Yen, up to 2017 Dec 29\n",
    "seriesnames=['DEXSZUS','DEXUSUK','DEXJPUS']\n",
    "cdates,ratematrix=qf.GetFREDMatrix(seriesnames,enddate=lastday2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017 = pd.DataFrame(ratematrix, index =cdates, columns = seriesnames)\n",
    "data2017 = data2017.set_index(pd.DatetimeIndex(data2017.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017_clean=data2017.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11788"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2017_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>DEXJPUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971-01-04</th>\n",
       "      <td>4.3180</td>\n",
       "      <td>2.3938</td>\n",
       "      <td>357.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-05</th>\n",
       "      <td>4.3117</td>\n",
       "      <td>2.3949</td>\n",
       "      <td>357.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-06</th>\n",
       "      <td>4.3113</td>\n",
       "      <td>2.3967</td>\n",
       "      <td>357.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-07</th>\n",
       "      <td>4.3103</td>\n",
       "      <td>2.3963</td>\n",
       "      <td>357.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-08</th>\n",
       "      <td>4.3109</td>\n",
       "      <td>2.3972</td>\n",
       "      <td>357.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            DEXSZUS  DEXUSUK  DEXJPUS\n",
       "1971-01-04   4.3180   2.3938   357.73\n",
       "1971-01-05   4.3117   2.3949   357.81\n",
       "1971-01-06   4.3113   2.3967   357.86\n",
       "1971-01-07   4.3103   2.3963   357.87\n",
       "1971-01-08   4.3109   2.3972   357.82"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2017_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if there is any row that has negative value in data2017_clean\n",
    "for each in seriesnames:\n",
    "    print(len(data2017_clean[data2017_clean[each] < 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wangc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\wangc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data2017_clean['DEXSZUS']=data2017_clean['DEXSZUS'].apply(lambda x: 1/x)\n",
    "data2017_clean['DEXJPUS']=data2017_clean['DEXJPUS'].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>DEXJPUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971-01-04</th>\n",
       "      <td>0.231589</td>\n",
       "      <td>2.3938</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-05</th>\n",
       "      <td>0.231927</td>\n",
       "      <td>2.3949</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-06</th>\n",
       "      <td>0.231949</td>\n",
       "      <td>2.3967</td>\n",
       "      <td>0.002794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-07</th>\n",
       "      <td>0.232002</td>\n",
       "      <td>2.3963</td>\n",
       "      <td>0.002794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-08</th>\n",
       "      <td>0.231970</td>\n",
       "      <td>2.3972</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DEXSZUS  DEXUSUK   DEXJPUS\n",
       "1971-01-04  0.231589   2.3938  0.002795\n",
       "1971-01-05  0.231927   2.3949  0.002795\n",
       "1971-01-06  0.231949   2.3967  0.002794\n",
       "1971-01-07  0.232002   2.3963  0.002794\n",
       "1971-01-08  0.231970   2.3972  0.002795"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2017_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>DEXJPUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971-01-04</th>\n",
       "      <td>-1.462792</td>\n",
       "      <td>0.872882</td>\n",
       "      <td>-5.879779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-05</th>\n",
       "      <td>-1.461332</td>\n",
       "      <td>0.873341</td>\n",
       "      <td>-5.880002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-06</th>\n",
       "      <td>-1.461239</td>\n",
       "      <td>0.874093</td>\n",
       "      <td>-5.880142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-07</th>\n",
       "      <td>-1.461008</td>\n",
       "      <td>0.873926</td>\n",
       "      <td>-5.880170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-08</th>\n",
       "      <td>-1.461147</td>\n",
       "      <td>0.874301</td>\n",
       "      <td>-5.880030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DEXSZUS   DEXUSUK   DEXJPUS\n",
       "1971-01-04 -1.462792  0.872882 -5.879779\n",
       "1971-01-05 -1.461332  0.873341 -5.880002\n",
       "1971-01-06 -1.461239  0.874093 -5.880142\n",
       "1971-01-07 -1.461008  0.873926 -5.880170\n",
       "1971-01-08 -1.461147  0.874301 -5.880030"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute log to all the values in the dataset\n",
    "data2017_new1=data2017_clean.apply(lambda x: np.log(x))\n",
    "data2017_new1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>DEXJPUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-22</th>\n",
       "      <td>-0.000809</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-26</th>\n",
       "      <td>0.000707</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>0.000883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>-0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>0.009774</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.003803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DEXSZUS   DEXUSUK   DEXJPUS\n",
       "2017-12-22 -0.000809  0.000523  0.001059\n",
       "2017-12-26  0.000707 -0.000748  0.000883\n",
       "2017-12-27  0.002125  0.002540 -0.000706\n",
       "2017-12-28  0.009774  0.003501  0.003803\n",
       "2017-12-29  0.003690  0.005856  0.001419"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the first difference and drop NA\n",
    "data2017_final=data2017_new1.diff()\n",
    "data2017_final.dropna(inplace=True)\n",
    "data2017_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11787"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check length\n",
    "len(data2017_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(data2017_final[seriesnames])\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2635 -0.4841  0.98  ] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5278 0.253  0.2247]\n",
      "C= [0.253  0.3594 0.1191]     (4.20)\n",
      "   [0.2247 0.1191 0.4209]\n",
      "(%/day)² units\n",
      "  \n",
      "From 1971-01-05 00:00:00 to 2017-12-29 00:00:00 ( 11787 observations)\n"
     ]
    }
   ],
   "source": [
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c[0]*10000)\n",
    "print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",data2017_final.index[0],\"to\",data2017_final.index[-1],\"(\",len(data2017_final),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           [ 3.3591 -1.9539 -1.2402]\n",
      "C-inverse= [-1.9539  4.2071 -0.1474]     (4.21)\n",
      "           [-1.2402 -0.1474  3.0796]\n",
      "(days/%)² units\n"
     ]
    }
   ],
   "source": [
    "# compute inverse of C\n",
    "ci=np.linalg.inv(c)\n",
    "print(\"          \",ci[0]/10000)\n",
    "#Jupyter doesn't like this superscript\n",
    "#print(f'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}=',ci[1]/10000,\"    (4.21)\")\n",
    "print(f'C-inverse=',ci[1]/10000,\"    (4.21)\")\n",
    "print(\"          \",ci[2]/10000)\n",
    "print(f'(days/%)\\N{SUPERSCRIPT TWO} units')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 3.9626538250355283 (days/%)²\n",
      "u'(C-inverse)m = 0.8471614302272519 days\n",
      "m'(C-inverse)m = 8.765622671007103 bps\n"
     ]
    }
   ],
   "source": [
    "#sum entries in ci\n",
    "uciu=np.sum(ci)\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "\n",
    "ucim=np.sum(np.matmul(ci,m))\n",
    "print(f'u\\'(C-inverse)m =',ucim, 'days')\n",
    "mcim=np.matmul(m,np.matmul(ci,m))\n",
    "print(f'm\\'(C-inverse)m =',mcim*10000,'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weight for the minimum variance portfolio\n",
    "u_vec=[1]*3\n",
    "w_optimal=(np.matmul(ci,u_vec))/uciu\n",
    "\n",
    "# compute the minimum variance\n",
    "variance_minimize=1/uciu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.0416, 0.5314, 0.427 ]), 2.523561340842167e-05)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the optimal weight and variance of the portfolio\n",
    "w_optimal, variance_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute LedoitWolf estimate using 1971 to 2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use directly the given s=1/3\n",
    "s_wolf=1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the three-currency correlation matrix \n",
    "prev_sig=np.sqrt(np.diag(np.diag(c)))\n",
    "prev_sig_inverse=np.linalg.inv(prev_sig)\n",
    "prev_r_matrix=np.matmul(np.matmul(prev_sig_inverse,c),prev_sig_inverse)\n",
    "prev_dim=len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average correlation (off-diagonal)\n",
    "prev_avg_corr=(np.sum(prev_r_matrix)-prev_dim)/(prev_dim**2-prev_dim)\n",
    "# Get average variance\n",
    "prev_avg_variance=np.matrix.trace(c)/prev_dim\n",
    "# Centralized prior\n",
    "prev_prior=prev_avg_variance*(np.ones((prev_dim,prev_dim))*prev_avg_corr+np.identity(prev_dim)*(1-prev_avg_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ledoit-Wolf estimate\n",
    "ledoit_wolf_est = np.multiply(1-s_wolf,c) + np.multiply(s_wolf, prev_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9723e-05, 2.3475e-05, 2.1586e-05],\n",
       "       [2.3475e-05, 3.8493e-05, 1.4547e-05],\n",
       "       [2.1586e-05, 1.4547e-05, 4.2595e-05]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ledoit_wolf_est=ledoit_wolf_est\n",
    "ledoit_wolf_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 3.9626538250355283 (days/%)²\n",
      "u'(C-inverse)m = 0.8471614302272519 days\n",
      "m'(C-inverse)m = 8.765622671007103 bps\n"
     ]
    }
   ],
   "source": [
    "# inverse\n",
    "ci_wolf=np.linalg.inv(ledoit_wolf_est)\n",
    "\n",
    "#sum entries in ci\n",
    "uciu_wolf=np.sum(ci_wolf)\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "\n",
    "ucim_wolf=np.sum(np.matmul(ci_wolf,m))\n",
    "print(f'u\\'(C-inverse)m =',ucim, 'days')\n",
    "mcim_wolf=np.matmul(m,np.matmul(ci_wolf,m))\n",
    "print(f'm\\'(C-inverse)m =',mcim*10000,'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weight using Ledoit-Wolf estimate\n",
    "u_vec=[1]*3\n",
    "w_optimal_wolf=(np.matmul(ci_wolf,u_vec))/uciu_wolf\n",
    "\n",
    "# compute the minimum variance\n",
    "variance_minimize_wolf=1/uciu_wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1523, 0.4518, 0.3959]), 2.672456015922548e-05)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the optimal weight and variance of the portfolio using ledoit wolf estimate\n",
    "w_optimal_wolf, variance_minimize_wolf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use 2018 data to compute minimum variance portfolio w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdates2018, ratematrix2018 = qf.GetFREDMatrix(seriesnames, startdate='2018-01-01', enddate='2018-12-31')\n",
    "\n",
    "nobs, t = len(cdates2018), 0\n",
    "while t < nobs:\n",
    "    if all(np.isnan(ratematrix2018[t])):\n",
    "        del ratematrix2018[t]\n",
    "        del cdates2018[t]\n",
    "        nobs -= 1\n",
    "    else:\n",
    "        t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018 = pd.DataFrame(ratematrix2018, index =cdates2018, columns = seriesnames)\n",
    "data2018 = data2018.set_index(pd.DatetimeIndex(data2018.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018['DEXSZUS']=data2018['DEXSZUS'].apply(lambda x: 1/x)\n",
    "data2018['DEXJPUS']=data2018['DEXJPUS'].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEXSZUS</th>\n",
       "      <th>DEXUSUK</th>\n",
       "      <th>DEXJPUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>1.029018</td>\n",
       "      <td>1.3596</td>\n",
       "      <td>0.008914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>1.024380</td>\n",
       "      <td>1.3522</td>\n",
       "      <td>0.008906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>1.025326</td>\n",
       "      <td>1.3539</td>\n",
       "      <td>0.008867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>1.025431</td>\n",
       "      <td>1.3562</td>\n",
       "      <td>0.008835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>1.024380</td>\n",
       "      <td>1.3566</td>\n",
       "      <td>0.008843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DEXSZUS  DEXUSUK   DEXJPUS\n",
       "2018-01-02  1.029018   1.3596  0.008914\n",
       "2018-01-03  1.024380   1.3522  0.008906\n",
       "2018-01-04  1.025326   1.3539  0.008867\n",
       "2018-01-05  1.025431   1.3562  0.008835\n",
       "2018-01-08  1.024380   1.3566  0.008843"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute log to all the values in the dataset\n",
    "data2018=data2018.apply(lambda x: np.log(x))\n",
    "# data2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the first difference and drop NA\n",
    "data2018_final=data2018.diff()\n",
    "data2018_final.dropna(inplace=True)\n",
    "#data2018_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check length\n",
    "#len(data2018_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d2018=np.array(data2018_final[seriesnames])\n",
    "m2018=np.mean(d2018,axis=0)\n",
    "c2018=np.cov(d2018.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2635 -0.4841  0.98  ] bps/day\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.1338 0.0892 0.0688]\n",
      "C= [0.0892 0.2402 0.0361]     (4.20)\n",
      "   [0.0688 0.0361 0.1579]\n",
      "(%/day)² units\n",
      "  \n",
      "From 2018-01-03 00:00:00 to 2018-12-31 00:00:00 ( 248 observations)\n"
     ]
    }
   ],
   "source": [
    "#display the output\n",
    "#vectors and matrices are in fractional units;\n",
    "#    fraction*100=percent\n",
    "#    fraction*10000=basis point\n",
    "#    (fraction^2)*10000=percent^2\n",
    "np.set_printoptions(precision=4)\n",
    "print(\"Means:\",m*10000,\"bps/day\")\n",
    "print(\"(CHF, GBP, JPY)\\n\")\n",
    "print(\"  \",c2018[0]*10000)\n",
    "print(\"C=\",c2018[1]*10000,\"    (4.20)\")\n",
    "print(\"  \",c2018[2]*10000)\n",
    "print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "print(\"  \")\n",
    "print(\"From\",data2018_final.index[0],\"to\",data2018_final.index[-1],\"(\",len(data2018_final),\"observations)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 10.168178978599139 (days/%)²\n"
     ]
    }
   ],
   "source": [
    "# compute inverse of C\n",
    "ci2018=np.linalg.inv(c2018)\n",
    "\n",
    "#sum entries in ci\n",
    "uciu2018=np.sum(ci2018)\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu2018/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "\n",
    "# compute the weight for the minimum variance portfolio\n",
    "u_vec2018=[1]*3\n",
    "w_optimal2018=(np.matmul(ci2018,u_vec2018))/uciu2018\n",
    "\n",
    "# compute the minimum variance\n",
    "variance_minimize2018=1/uciu2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weight for the minimum variance portfolio\n",
    "u_vec2018=[1]*3\n",
    "w_optimal2018=(np.matmul(ci2018,u_vec2018))/uciu2018\n",
    "\n",
    "# compute the minimum variance\n",
    "variance_minimize2018=1/uciu2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.3907, 0.2033, 0.406 ]), 9.834602657021378e-06)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the optimal weight and variance of the portfolio\n",
    "w_optimal2018, variance_minimize2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute LedoitWolf estimate using 2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use directly the given s=1/3\n",
    "s_wolf=1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the three-currency correlation matrix \n",
    "prev_sig_2018=np.sqrt(np.diag(np.diag(c2018)))\n",
    "prev_sig_inverse_2018=np.linalg.inv(prev_sig)\n",
    "prev_r_matrix_2018=np.matmul(np.matmul(prev_sig_inverse,c2018),prev_sig_inverse)\n",
    "prev_dim_2018=len(c2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average correlation (off-diagonal)\n",
    "prev_avg_corr_2018=(np.sum(prev_r_matrix_2018)-prev_dim_2018)/(prev_dim_2018**2-prev_dim_2018)\n",
    "# Get average variance\n",
    "prev_avg_variance_2018=np.matrix.trace(c2018)/prev_dim_2018\n",
    "# Centralized prior\n",
    "prev_prior_2018=prev_avg_variance_2018*(np.ones((prev_dim_2018,prev_dim_2018))*prev_avg_corr_2018+np.identity(prev_dim_2018)*(1-prev_avg_corr_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ledoit-Wolf estimate\n",
    "ledoit_wolf_est_2018 = np.multiply(1-s_wolf,c2018) + np.multiply(s_wolf, prev_prior_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4829e-05, 5.1423e-06, 3.7847e-06],\n",
       "       [5.1423e-06, 2.1921e-05, 1.6059e-06],\n",
       "       [3.7847e-06, 1.6059e-06, 1.6437e-05]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ledoit_wolf_est_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u'(C-inverse)u = 12.357659500429824 (days/%)²\n"
     ]
    }
   ],
   "source": [
    "# inverse\n",
    "ci_wolf_2018=np.linalg.inv(ledoit_wolf_est_2018)\n",
    "\n",
    "#sum entries in ci\n",
    "uciu_wolf_2018=np.sum(ci_wolf_2018)\n",
    "#print(f'u\\'C\\N{SUPERSCRIPT MINUS}\\N{SUPERSCRIPT ONE}u =',uciu/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')\n",
    "print(f'u\\'(C-inverse)u =',uciu_wolf_2018/10000, f'(days/%)\\N{SUPERSCRIPT TWO}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the weight using Ledoit-Wolf estimate\n",
    "u_vec=[1]*3\n",
    "w_optimal_wolf_2018=(np.matmul(ci_wolf_2018,u_vec))/uciu_wolf_2018\n",
    "\n",
    "# compute the minimum variance\n",
    "variance_minimize_wolf_2018=1/uciu_wolf_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.3584, 0.2569, 0.3847]), 8.092147222256917e-06)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the optimal weight and variance of the portfolio using ledoit wolf estimate\n",
    "w_optimal_wolf_2018, variance_minimize_wolf_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "#### Using 1971 to 2017 data:\n",
    "\n",
    "The minimum variance portfolio is below:\n",
    "1971-01-05 to 2017-12-29: optimal weight w1 and variance is w1=[0.0416, 0.5314, 0.427 ], variance=2.523561340842167e-05.\n",
    "\n",
    "Use Ledoit-Wolf shrinkage (with s=1/3) on this matrix, minimum variance portfolio is below:\n",
    "1971-01-05 to 2017-12-29: optimal weight w2 and variance is w2=[0.1523, 0.4518, 0.3959], variance= 2.672456015922548e-05.\n",
    "\n",
    "#### Using 2018-01-01 to 2018-12-31 data only:\n",
    "\n",
    "The minimum variance portfolio is below:\n",
    "Optimal weight w1 and variance is: w1=[0.3907, 0.2033, 0.406 ], variance=9.834602657021356e-06.\n",
    "\n",
    "Use Ledoit-Wolf shrinkage (with s=1/3) on this matrix, minimum variance portfolio is below:\n",
    "Optimal weight w2 and variance is: w2=[0.3668, 0.2395, 0.3937]), variance=1.011237712216552e-05\n",
    "\n",
    "We can see that using Ledoit_wolf shrinkage estimator, the minimum variance of the portfolio is actually larger than using the sample covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
