{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Binqian Zeng **\n",
    "\n",
    "**NetID: bz866 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qrbook_funcs as qf\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "# Get 3 currencies until the end of Dec 29, 2017\n",
    "# From sample covariance matrix and do simple efficient frontier calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minimum_variance_portfolio(startday=None, lastday=None, display=True):\n",
    "    \"\"\"\n",
    "    @startday: optional, 'YYYY-MM-DD' dates\n",
    "    @lastday: optional, 'YYYY-MM-DD' dates\n",
    "    Return: \n",
    "        The mean of return of each instrument\n",
    "        The covariance matrix of return of instruments\n",
    "    \"\"\"\n",
    "    # Swiss Francs, pound sterling, Japanese Yen\n",
    "    seriesnames = ['DEXSZUS', 'DEXUSUK', 'DEXJPUS']\n",
    "    cdates, ratematrix = qf.GetFREDMatrix(seriesnames, startdate=startday, enddate=lastday)\n",
    "    \n",
    "    # Convert levels to log-returns\n",
    "    # First take logs of the currency levels\n",
    "    # Currency exchange rates are usually expressed in the direction\n",
    "    # that will make the rate > 1\n",
    "    # Swissie and yen are in currency/dollar, but\n",
    "    # pounds is in dollar/currency. Reverse signs\n",
    "    # so everything is in dollar/currency\n",
    "\n",
    "    # Do each currency separately to account for separate missing data patterns\n",
    "    # dlgs is a list of lists of length 3 corresponding to the 3 currencies\n",
    "    # The value in dlgs is nan if there is missing data for the present or previous day's observation\n",
    "    # Otherwise it is the log of today/yesterday\n",
    "\n",
    "    multipliers=[-1,1,-1]\n",
    "    dlgs=[]\n",
    "    for i in range(len(multipliers)):\n",
    "        lgrates=[]\n",
    "        previous=-1\n",
    "        for t in range(len(ratematrix)):\n",
    "            if pd.isna(ratematrix[t][i]) or ratematrix[t][i]<=0:\n",
    "                lgrates.append(np.nan)    # Append a nan\n",
    "            else:\n",
    "                if previous < 0:    # This is the first data point\n",
    "                    lgrates.append(np.nan)\n",
    "                else:\n",
    "                    lgrates.append(np.log(ratematrix[t][i]/previous)*multipliers[i])\n",
    "                previous=ratematrix[t][i]\n",
    "        dlgs.append(lgrates)\n",
    "\n",
    "    # dlgs is the transpose of what we want - flip it\n",
    "    dlgs=np.transpose(dlgs)\n",
    "\n",
    "    # Delete any time periods that don't have data\n",
    "    lgdates=[]\n",
    "    difflgs=[]\n",
    "    for t in range(len(dlgs)):\n",
    "        if all(pd.notna(dlgs[t])):\n",
    "            #include this time period\n",
    "            difflgs.append(dlgs[t])\n",
    "            lgdates.append(cdates[t])\n",
    "\n",
    "    # Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "    d=np.array(difflgs)\n",
    "    m=np.mean(d,axis=0)\n",
    "    c=np.cov(d.T)\n",
    "\n",
    "    # display the output\n",
    "    # vectors and matrices are in fractional units;\n",
    "    #    fraction*100=percent\n",
    "    #    fraction*10000=basis point\n",
    "    #    (fraction^2)*10000=percent^2\n",
    "    if display:\n",
    "        np.set_printoptions(precision=4)\n",
    "        print(\"Means:\",m*10000,\"bps/day\")\n",
    "        print()\n",
    "        print(\"The minimum variance portfolio\")\n",
    "        print(\"(CHF, GBP, JPY)\\n\")\n",
    "        print(\"  \",c[0]*10000)\n",
    "        print(\"C=\",c[1]*10000,\"    (4.20)\")\n",
    "        print(\"  \",c[2]*10000)\n",
    "        print(f'(%/day)\\N{SUPERSCRIPT TWO} units')\n",
    "        print(\"  \")\n",
    "        print(\"From\",lgdates[0],\"to\",lgdates[-1],\"(\",len(lgdates),\"observations)\")\n",
    "        print('-------------------')\n",
    "        print()\n",
    "        \n",
    "    return m, c\n",
    "\n",
    "def portfolio_annualized_performance(weights, meanReturns, covReturnMtx):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation and returns of a portfolio\n",
    "    @weights: 1-d array\n",
    "    @meanReturns: 1-d array\n",
    "    @covReturnMtx: 2-d array\n",
    "    Return:\n",
    "        The standard deviation of the portfolio\n",
    "    \"\"\"\n",
    "    returns = np.sum(meanReturns*weights) * 252 # annualized return\n",
    "    std = np.sqrt(np.dot(weights.T, np.dot(covReturnMtx, weights))) * np.sqrt(252) # standard deviation\n",
    "    return std, returns\n",
    "\n",
    "def portfolio_volatility(weights, meanReturns, covReturnMtx):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation of the portfolio as the volatility\n",
    "    @weights: 1-d array\n",
    "    @meanReturns: 1-d array\n",
    "    @covReturnMtx: 2-d array\n",
    "    Return:\n",
    "        The standard deviation of the portfolio\n",
    "    \"\"\"\n",
    "    std, _ = portfolio_annualized_performance(weights, meanReturns, covReturnMtx)\n",
    "    return std\n",
    "\n",
    "def min_volatility(meanReturns, covReturnMtx):\n",
    "    \"\"\"\n",
    "    Calculate the possible minimum variance to achieve given means of return \n",
    "    and covariance matrix of returns\n",
    "    @meanReturns: 1-d array\n",
    "    @covReturnMtx: 2-d array\n",
    "    Return:\n",
    "        The set up to achieve the minimum variance\n",
    "    \"\"\"\n",
    "    numAssets = len(meanReturns)\n",
    "    args = (meanReturns, covReturnMtx)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0, 1.0)\n",
    "    bounds = tuple(bound for i in range(numAssets))\n",
    "    \n",
    "    weights0 = [1 / numAssets for i in range(numAssets)] # initalize weights as evenly distributed\n",
    "    # Optimize\n",
    "    minVolatilitySetUp = optimize.minimize(portfolio_volatility, weights0, args=args, \n",
    "                                   method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return minVolatilitySetUp\n",
    "\n",
    "def calculate_efficient_frontier(seriesnames, meanReturns, covReturnMtx, numPortfolios=10000, display=True):\n",
    "    \"\"\"\n",
    "    Caculate the efficient frontier for the portfolio\n",
    "    @meanReturns: 1-d array\n",
    "    @covReturnMtx: 2-d array\n",
    "    @numPortfolios: default 10000\n",
    "    @display: boolean\n",
    "    Return:\n",
    "        display a table of return, volatility, and allocation\n",
    "    \"\"\"\n",
    "    minVolatilitySetUp = min_volatility(meanReturns, covReturnMtx)\n",
    "    stdMinPrtf, returnMin = portfolio_annualized_performance(minVolatilitySetUp['x'], meanReturns, covReturnMtx)\n",
    "    minVolatilityAlloc = pd.DataFrame(minVolatilitySetUp['x'], index=seriesnames, columns=['allocation percentage'])\n",
    "    minVolatilityAlloc['allocation percentage'] = [round(i * 100, 2) for i in minVolatilityAlloc['allocation percentage']]\n",
    "    minVolatilityAlloc = minVolatilityAlloc.T\n",
    "    \n",
    "    if display:\n",
    "        print (\"Minimum Volatility Portfolio Allocation Percentage\\n\")\n",
    "        print (\"Annualised Return:\", round(returnMin,2))\n",
    "        print (\"Annualised Volatility:\", round(stdMinPrtf,2))\n",
    "        print (\"\\n\")\n",
    "        print (minVolatilityAlloc)\n",
    "        print (\"--------------------------------\")\n",
    "    \n",
    "    \n",
    "def calculate_efficient_frontier_return(seriesnames, meanReturns, covReturnMtx, numPortfolios=10000, display=True):\n",
    "    \"\"\"\n",
    "    Caculate the efficient frontier for the portfolio\n",
    "    @meanReturns: 1-d array\n",
    "    @covReturnMtx: 2-d array\n",
    "    @numPortfolios: default 10000\n",
    "    @display: boolean\n",
    "    Return:\n",
    "        display a table of return, volatility, and allocation\n",
    "    \"\"\"\n",
    "    minVolatilitySetUp = min_volatility(meanReturns, covReturnMtx)\n",
    "    stdMinPrtf, returnMin = portfolio_annualized_performance(minVolatilitySetUp['x'], meanReturns, covReturnMtx)\n",
    "    minVolatilityAlloc = pd.DataFrame(minVolatilitySetUp['x'], index=seriesnames, columns=['allocation percentage'])\n",
    "    minVolatilityAlloc['allocation percentage'] = [round(i * 100, 2) for i in minVolatilityAlloc['allocation percentage']]\n",
    "    minVolatilityAlloc = minVolatilityAlloc.T\n",
    "    \n",
    "    if display:\n",
    "        print (\"Minimum Volatility Portfolio Allocation Percentage\\n\")\n",
    "        print (\"Annualised Return:\", round(returnMin,2))\n",
    "        print (\"Annualised Volatility:\", round(stdMinPrtf,2))\n",
    "        print (\"\\n\")\n",
    "        print (minVolatilityAlloc)\n",
    "        print (\"--------------------------------\")\n",
    "    \n",
    "    return np.ndarray.flatten(minVolatilityAlloc.values) / 100\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_prft_return(weights, returns):\n",
    "    \"\"\"\n",
    "    Calculate the expected return of given portfolio\n",
    "    @weights: 1-d array, floats\n",
    "    @returns: 1-d array, floats\n",
    "    Return:\n",
    "        float; the expected return of the portfolio\n",
    "    \"\"\"\n",
    "    return np.matmul( weights, returns.T )\n",
    "\n",
    "def variance_prtf( weights, C):\n",
    "    \"\"\"\n",
    "    Calculate the variance of the portfolio\n",
    "    @weights: 1-d array, floats\n",
    "    @C: 2-d array, covariance matrix\n",
    "    Return:\n",
    "        float; the variance of the portfolio\n",
    "    \"\"\"\n",
    "    return np.matmul( np.matmul( weights, C) , weights.T )\n",
    "\n",
    "def beta_vec(weights, C):\n",
    "    \"\"\"\n",
    "    Calculate the vector of betas \n",
    "    @weights: 1-d array, floats\n",
    "    @C: 2-d array, covariance matrix\n",
    "    Return:\n",
    "        1-d array; the vector of betas\n",
    "    \"\"\"\n",
    "    return np.matmul( C, weights ) / variance_prtf(weights, C)\n",
    "\n",
    "def muCAPM_calculation(weights, returns, C, RFRATE, RFVEC):\n",
    "    \"\"\"\n",
    "    Calculate the mu of the CAPM\n",
    "    @weights: 1-d array, floats\n",
    "    @returns: 1-d array, floats\n",
    "    @C: 2-d array, covariance matrix\n",
    "    @RFRATE: float, default \n",
    "    @RFVEC: 1-d array of [RFRATE] * DIM\n",
    "    Return:\n",
    "        1-d array; The expected return of the CAPM\n",
    "    \"\"\"\n",
    "#     return RFVEC + (expected_prft_return(weights, returns) * 10000 - RFRATE ) * beta_vec(weights, C)\n",
    "    return RFVEC + np.multiply(10000, RFVEC + ( expected_prft_return(weights, returns) - RFRATE ) * beta_vec(weights, C) )\n",
    "\n",
    "def calculate_termA(view, gamma, s, C, display=True):\n",
    "    \"\"\"\n",
    "    Calculate the First Black-Litterman term to calculate the mu \n",
    "    @view: 1-d array; opinion\n",
    "    @gamma: float\n",
    "    @C: 2-d array\n",
    "    Return:\n",
    "        2-d array; The first Black-Litterman Matrix\n",
    "    \"\"\"\n",
    "    termOne = np.linalg.inv(C) / s\n",
    "    v1 = np.matmul( np.matrix(view).T, np.linalg.inv(gamma) )\n",
    "    termTwo = np.matmul( v1 , \n",
    "                         np.matrix( view )\n",
    "                       )\n",
    "    termA = np.linalg.inv(termOne + termTwo) # \n",
    "    if display:\n",
    "        print('C-inverse/s = ', termOne)\n",
    "        print('V\\'(Gamma-inverse)V=', termTwo)\n",
    "        print('Sum=', termOne + termTwo)\n",
    "        print('Sum inverse (*10000)=', termA * 10000)\n",
    "    \n",
    "    return termA\n",
    "\n",
    "def calculate_termB(view, gamma, s, pview, weights, returns, C, RFRATE, RFVEC, display=True):\n",
    "    \"\"\"\n",
    "    Calculate the Second Black-Litterman term to calculate the mu\n",
    "    @view: 1-d array; opinion\n",
    "    @gamma: float\n",
    "    @C: 2-d array\n",
    "    @weights: 1-d array, floats\n",
    "    @returns: 1-d array, floats\n",
    "    @RFRATE: float, default \n",
    "    @RFVEC: 1-d array of [RFRATE] * DIM\n",
    "    \"\"\"\n",
    "    CInv = np.linalg.inv(C)\n",
    "    cimcs = np.matmul(CInv, muCAPM_calculation(weights, returns, C, RFRATE, RFVEC) / s) * 10 ** (-4)\n",
    "    m2 = cimcs + np.matmul( np.matrix(view).T, np.linalg.inv(gamma) ).T * pview\n",
    "    if display:\n",
    "        print('C-inverse*muCAPM/s=', cimcs)\n",
    "        print('V\\'(Gamma-Inverse)p=', np.matmul( np.matrix(view).T, np.linalg.inv(gamma) ) * pview)\n",
    "        print(\"Sum = \", m2)\n",
    "        \n",
    "    return m2\n",
    "\n",
    "def calculate_mufinal(view, gamma, s, pview, weights, returns, C, RFRATE, RFVEC, display=True):\n",
    "    \"\"\"\n",
    "    calculate the mufinal\n",
    "    \"\"\"\n",
    "    termA = calculate_termA(view, gamma, s, C, display=False)\n",
    "    termB = calculate_termB(view, gamma, s, pview, weights, returns, C, RFRATE, RFVEC, display=False)\n",
    "    mufinal = np.matmul( termA, termB.T) * 10000\n",
    "    if display:\n",
    "        print(\"Black-Litterman mu: \", mufinal)\n",
    "    \n",
    "    return mufinal\n",
    "\n",
    "def loss_func(s, view, gamma, pview, weights, returns, C, RFRATE, RFVEC):\n",
    "    mufinal = calculate_mufinal(view, gamma, s, pview, weights, returns, C, RFRATE, RFVEC, display=False)\n",
    "    mufinalFlat = np.asarray(mufinal).reshape(-1)\n",
    "#     mufinalFlat = np.ndarray.tolist(mufinal)\n",
    "    print(type(mufinal))\n",
    "    print(np.asarray(mufinal).reshape(-1))\n",
    "    print(mufinalFlat[0])\n",
    "    return abs(mufinalFlat[1]**2 - mufinalFlat[2]**2) # GLS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 3 # three currencies\n",
    "RFRATE = 10**(-5) # Same default RFRATE as text book\n",
    "RFVEC = [RFRATE] * DIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get the expected return for \"CHF\", \"GBP\", \"JPY\" in the history, from the begining of 1971 to the end of 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2138 -0.5389  0.9821] bps/day\n",
      "\n",
      "The minimum variance portfolio\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5194 0.2494 0.2207]\n",
      "C= [0.2494 0.3568 0.1166]     (4.20)\n",
      "   [0.2207 0.1166 0.4155]\n",
      "(%/day)² units\n",
      "  \n",
      "From 1971-01-05 to 2018-12-31 ( 12036 observations)\n",
      "-------------------\n",
      "\n",
      "Market mu = 0.7655 bps/day\n",
      "Market sigma² = 0.3246 (%/day)²\n"
     ]
    }
   ],
   "source": [
    "# Historical market for the three currencies\n",
    "# The minimum variance portfolio\n",
    "# from Jan 01, 1971 to Dec 31, 2018\n",
    "means20181231, covReturnMtx20181231 = get_minimum_variance_portfolio(startday='1971-01-01', \n",
    "                                                                     lastday='2018-12-31')\n",
    "\n",
    "# The minimum variance portfolio ending on Dec 31, 2018\n",
    "# mktPrtf = calculate_efficient_frontier_return([\"CHF\", \"GBP\", \"JPY\"], means20181231, covReturnMtx20181231)\n",
    "mktPrtf = np.array([.05, .15, .8])\n",
    "\n",
    "muMkt = expected_prft_return(mktPrtf, means20181231)\n",
    "print('Market mu = {0:.4f} bps/day'.format(muMkt * 10000))\n",
    "varMkt = variance_prtf(mktPrtf, covReturnMtx20181231)\n",
    "print(\"Market sigma\\N{SUPERSCRIPT TWO} = {0:.4f} (%/day)\\N{SUPERSCRIPT TWO}\".format(varMkt * 10000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute the vector of betas of the three currencies assets with the market, and form that the $\\mu_{CAPM}$ vector given by \n",
    "$$ \\mu_{CAPM} = r_{f}u + (m^{T}\\omega_{M} - r_{f} ) \\beta $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = [0.7391 0.4906 1.1118]\n",
      "mu-CAPM = [0.5919 0.4265 0.8399] bps/day\n"
     ]
    }
   ],
   "source": [
    "betaVec = beta_vec(mktPrtf, covReturnMtx20181231)\n",
    "print(\"beta = {}\".format(betaVec))\n",
    "\n",
    "muCAPM = muCAPM_calculation(mktPrtf, means20181231, covReturnMtx20181231, RFRATE, RFVEC)\n",
    "print(\"mu-CAPM = {} bps/day\".format(muCAPM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "Now we have an opinion that the expected return on pounds equal to the expected return on yen. Since both the pound and the yen have positive return, we can long both currencies to have \n",
    "\n",
    "$$ p = 0.0000 $$\n",
    "$$ V = ( 0 , 1, 1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's assume the error of estimate matrix of our views is $\\Gamma = 0.0001 * I$, we initialize the market beliefs with $s = 0.5$.\n",
    "\n",
    "For the term a $$\\left(\\frac{1}{s}C^{-1}+V^{\\prime}\\Gamma^{-1}V\\right)^{-1}$$\n",
    "and term b $$ \\left(\\frac{1}{s}C^{-1}\\mu_{CAPM}+V^{\\prime}\\Gamma^{-1}V\\mu_{views}\\right)\\label{eq:black_litterman_overall_mu}\\tag{4.76}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEW = np.array([0, 1, -1]) # The opinion\n",
    "PVIEW = 0.00002\n",
    "GAMMA = np.matrix([.0001])\n",
    "s0 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizer(view, gamma, s0, pview, weights, returns, C, RFRATE, RFVEC, DIM):\n",
    "    numAssets = DIM\n",
    "    args = (view, gamma, pview, weights, returns, C, RFRATE, RFVEC)\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "    bound = (0.0, np.inf)\n",
    "    bounds = tuple(bound for i in range(numAssets))\n",
    "    \n",
    "    # Optimize\n",
    "    minDiffReturn = optimize.minimize(loss_func, s0, args=args, \n",
    "                                   method='nelder-mead', \n",
    "                                      options={'xtol': 1e-8, \n",
    "                                                                 'disp': True, \n",
    "                                                                 'maxiter': 500})\n",
    "    \n",
    "    return minDiffReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrix'>\n",
      "[0.6034 0.5222 0.7208]\n",
      "0.603390015504496\n",
      "<class 'numpy.matrix'>\n",
      "[0.6038 0.5253 0.717 ]\n",
      "0.6037560631642307\n",
      "<class 'numpy.matrix'>\n",
      "[0.6041 0.5283 0.7133]\n",
      "0.6041097236495401\n",
      "<class 'numpy.matrix'>\n",
      "[0.6045 0.5311 0.7098]\n",
      "0.6044516152775432\n",
      "<class 'numpy.matrix'>\n",
      "[0.6051 0.5365 0.703 ]\n",
      "0.6051023660976058\n",
      "<class 'numpy.matrix'>\n",
      "[0.6057 0.5416 0.6967]\n",
      "0.605712509122908\n",
      "<class 'numpy.matrix'>\n",
      "[0.6068 0.5509 0.6851]\n",
      "0.6068252826805127\n",
      "<class 'numpy.matrix'>\n",
      "[0.6078 0.5592 0.6748]\n",
      "0.6078145880580212\n",
      "<class 'numpy.matrix'>\n",
      "[0.6095 0.5732 0.6574]\n",
      "0.6094967817027066\n",
      "<class 'numpy.matrix'>\n",
      "[0.6109 0.5847 0.6431]\n",
      "0.6108734728498948\n",
      "<class 'numpy.matrix'>\n",
      "[0.613  0.6024 0.621 ]\n",
      "0.612992076153427\n",
      "<class 'numpy.matrix'>\n",
      "[0.6145 0.6154 0.6049]\n",
      "0.6145461940353878\n",
      "<class 'numpy.matrix'>\n",
      "[0.6167 0.6332 0.5828]\n",
      "0.6166735339240865\n",
      "<class 'numpy.matrix'>\n",
      "[0.6157 0.6253 0.5925]\n",
      "0.6157349086875958\n",
      "<class 'numpy.matrix'>\n",
      "[0.613  0.6024 0.621 ]\n",
      "0.612992076153427\n",
      "<class 'numpy.matrix'>\n",
      "[0.6138 0.6094 0.6124]\n",
      "0.6138245892597792\n",
      "<class 'numpy.matrix'>\n",
      "[0.613  0.6024 0.621 ]\n",
      "0.6129920761534271\n",
      "<class 'numpy.matrix'>\n",
      "[0.6142 0.6125 0.6085]\n",
      "0.6141978222780193\n",
      "<class 'numpy.matrix'>\n",
      "[0.6134 0.606  0.6166]\n",
      "0.6134237352011593\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.611  0.6104]\n",
      "0.6140144768425471\n",
      "<class 'numpy.matrix'>\n",
      "[0.6142 0.6125 0.6085]\n",
      "0.6141978222780193\n",
      "<class 'numpy.matrix'>\n",
      "[0.6139 0.6102 0.6114]\n",
      "0.6139203725108388\n",
      "<class 'numpy.matrix'>\n",
      "[0.6141 0.6117 0.6095]\n",
      "0.6141069460143396\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6106 0.6109]\n",
      "0.6139676317705342\n",
      "<class 'numpy.matrix'>\n",
      "[0.6139 0.6102 0.6114]\n",
      "0.6139203725108389\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6108 0.6107]\n",
      "0.6139911057389403\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.611  0.6104]\n",
      "0.6140144768425471\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6108]\n",
      "0.6139793816552358\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6109 0.6105]\n",
      "0.6140028041065384\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139852469168984\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6108]\n",
      "0.6139793816552358\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139881771322092\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6108]\n",
      "0.6139823150916829\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139867122257089\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139837812056117\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139859796216031\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139867122257089\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139856132818269\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139852469168984\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857964548584\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139859796216025\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857048691285\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139856132818269\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857506621902\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139856590756742\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857277657083\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139856819724502\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857163174312\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139856934208019\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857105932828\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857163174309\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857077312068\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857134553574\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857091622448\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857077312063\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857098777637\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857084467255\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857095200044\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857098777635\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857093411247\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857096988844\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857094305645\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857096094443\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857094752844\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857095647244\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857094976444\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857094752844\n",
      "<class 'numpy.matrix'>\n",
      "[0.614  0.6107 0.6107]\n",
      "0.6139857095088246\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 34\n",
      "         Function evaluations: 68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[3.8346],\n",
       "       [3.8346]]), array([9.6666e-11, 1.5925e-10]))\n",
       "           fun: 9.666550893072667e-11\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 68\n",
       "           nit: 34\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([3.8346])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize\n",
    "minimizer(VIEW, GAMMA, s0, PVIEW, mktPrtf, means20181231,\n",
    "          covReturnMtx20181231, RFRATE, RFVEC, DIM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The following is the new estimated mean return vector with the optimal s = 3.8346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.614 ],\n",
       "        [0.6107],\n",
       "        [0.6107]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The value of the first term\n",
    "calculate_mufinal(VIEW, GAMMA, 3.8346, PVIEW, mktPrtf, means20181231, covReturnMtx20181231, RFRATE, RFVEC, display=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The following of the first matrix \n",
    "$$\\left(\\frac{1}{s}C^{-1}+V^{\\prime}\\Gamma^{-1}V\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  8879.1972,  -5137.9581,  -3274.4752],\n",
       "        [ -5137.9581,  21020.6461, -10363.3218],\n",
       "        [ -3274.4752, -10363.3218,  18118.2625]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(calculate_termA(VIEW, GAMMA, 3.8346, covReturnMtx20181231, display=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The following of the second matrix \n",
    "$$ \\left(\\frac{1}{s}C^{-1}\\mu_{CAPM}+V^{\\prime}\\Gamma^{-1}V\\mu_{views}\\right)\\label{eq:black_litterman_overall_mu}\\tag{4.76}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.0314, 0.3354, 0.2726]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_termB(VIEW, GAMMA, 3.8346, PVIEW, mktPrtf, means20181231, covReturnMtx20181231, RFRATE, RFVEC, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [ 1.2476 -0.5009  0.98  ] bps/day\n",
      "\n",
      "The minimum variance portfolio\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.5276 0.2528 0.2239]\n",
      "C= [0.2528 0.3592 0.1183]     (4.20)\n",
      "   [0.2239 0.1183 0.4209]\n",
      "(%/day)² units\n",
      "  \n",
      "From 1971-01-05 to 2017-12-29 ( 11787 observations)\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The minimum variance portfolio\n",
    "# from Jan 01, 1971 to Dec 31, 2017\n",
    "means20171231, covReturnMtx20171231 = get_minimum_variance_portfolio(startday='1971-01-01', \n",
    "                                                                     lastday='2017-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Volatility Portfolio Allocation Percentage\n",
      "\n",
      "Annualised Return: 0.01\n",
      "Annualised Volatility: 0.08\n",
      "\n",
      "\n",
      "                        CHF    GBP    JPY\n",
      "allocation percentage  4.22  53.12  42.66\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The minimum variance portfolio ending on Dec 31, 2017\n",
    "calculate_efficient_frontier([\"CHF\", \"GBP\", \"JPY\"], means20171231, covReturnMtx20171231)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The following approach is using the Ledoit-Wolf heuristic covariance estimator as \n",
    "\n",
    "$$C_{\\rho} = S( I + \\rho_{\\text{average}}( J - I ) ) S $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LedoitWolf_constant_corr_cov_shrinkage_estimator(s, covMtxCurr, covMtxPrev):\n",
    "    \"\"\"\n",
    "    @s: float, constant\n",
    "    @covMtxCurr: 2-d array; the CURRENT constant correlation covariance Matrix \n",
    "    @covMtxPrev: 2-d array; the PREVIOUS constant correlation covariance Matrix \n",
    "    Return:\n",
    "        2-array; the UPDATED constant correlation covariance Matrix \n",
    "    \"\"\"\n",
    "    return s * covMtxCurr + (1 - s) * covMtxPrev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dimension of the portfolio and the covariance matrix\n",
    "DIM = 3 # 3 currencies example\n",
    "s = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum variance portfolio from the Ledoit-Wolf w2 is: [0.1013 0.5014 0.3972]\n"
     ]
    }
   ],
   "source": [
    "# Ledoit-Wolf heuristic covariance estimator\n",
    "\n",
    "# Form the three-currency correlation matrix as of previous year \n",
    "prevSig = np.sqrt( np.diag( np.diag( covReturnMtx20171231 ) ) )\n",
    "prevSigInv = np.linalg.inv(prevSig)\n",
    "prevRmtx = np.matmul( np.matmul (prevSigInv, covReturnMtx20171231 ), prevSigInv )\n",
    "\n",
    "# Get average correlation (off-diagonal)\n",
    "prevAvgCorr = ( np.sum( prevRmtx ) - DIM ) / ( DIM**2 - DIM)\n",
    "# Get the constant correlation covariance matrix\n",
    "innerTerm = np.identity(DIM) + prevAvgCorr * ( np.ones( (3, 3) ) - np.identity(3) )\n",
    "constCorrCovMtxCurr = np.matmul( np.matmul( prevSig, innerTerm) , prevSig )\n",
    "\n",
    "# Ledoit-Wolf estimate\n",
    "Crho = LedoitWolf_constant_corr_cov_shrinkage_estimator(s, constCorrCovMtxCurr, covReturnMtx20171231)\n",
    "\n",
    "# Inverse the Crho to convert the unit to (day/pct)^2\n",
    "CrhoInv = np.linalg.inv(Crho)\n",
    "\n",
    "# Get the minimum variance portfolio \n",
    "lower = np.sum(CrhoInv)\n",
    "u = np.ones(DIM)\n",
    "upper = np.matmul(CrhoInv, u)\n",
    "\n",
    "wMinVar = upper / lower\n",
    "\n",
    "print(\"The minimum variance portfolio from the Ledoit-Wolf w2 is: {}\".format(wMinVar) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "The minimum variance portfolio $w_{1}$ is [0.0422, 0.5312, 0.4266] for CHF, GBP, and JPY.\n",
    "\n",
    "The minimum variance portfolio $w_{2}$ is [0.1013 0.5014 0.3972] for CHF, GBP, and JPY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [-0.4703 -2.5494  0.9014] bps/day\n",
      "\n",
      "The minimum variance portfolio\n",
      "(CHF, GBP, JPY)\n",
      "\n",
      "   [0.1338 0.0892 0.0688]\n",
      "C= [0.0892 0.2402 0.0361]     (4.20)\n",
      "   [0.0688 0.0361 0.1579]\n",
      "(%/day)² units\n",
      "  \n",
      "From 2018-01-03 to 2018-12-31 ( 248 observations)\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from Jan 01 2018 to Dec 31, 2018\n",
    "means2018, covReturnMtx2018 = get_minimum_variance_portfolio(startday='2018-01-01', \n",
    "                                                                     lastday='2018-12-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance of w1 in 2018 is 0.1196006409\n",
      "The variance of w2 in 2018 is 0.1156774889\n"
     ]
    }
   ],
   "source": [
    "# The minimum variance portfolio ending on Dec 31, 2017\n",
    "prtfOne = calculate_efficient_frontier_return([\"CHF\", \"GBP\", \"JPY\"], means20171231, covReturnMtx20171231, display=False)\n",
    "\n",
    "# The minimum variance # The minimum variance portfolio ending on Dec 31, 2017 by Ledoit_Wolf\n",
    "prtfTwo = wMinVar\n",
    "\n",
    "# Convert percentage to bps\n",
    "covReturnMtx2018bps = covReturnMtx2018 * 10000\n",
    "\n",
    "# w1 variance in 2018\n",
    "varOne = np.matmul ( np.matmul( prtfOne, covReturnMtx2018bps ) , prtfOne.T )\n",
    "print(\"The variance of w1 in 2018 is {0:.10f}\".format(varOne) )\n",
    "\n",
    "# w2 variance in 2018\n",
    "varTwo = np.matmul ( np.matmul( prtfTwo, covReturnMtx2018bps ) , prtfTwo.T )\n",
    "print(\"The variance of w2 in 2018 is {0:.10f}\".format(varTwo) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "Obviously, the portfolio $w_{2}$ obtained from the Ledoit-Wolf shrinkage method is better than the one $w_{1}$ obtained from the historical covariance, which means the Ledoit-Wolf shrinkage method is a better estimator under the given circumstance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the question, we can have \n",
    "\n",
    "$$ P ( - | F ) = 95\\% $$\n",
    "$$ P ( + | S ) = 90\\% $$\n",
    "$$ P ( F ) = 15\\% $$\n",
    "\n",
    "From the previous, we can derive that \n",
    "\n",
    "$$ P ( - | S ) = 1 - P ( + | S ) = 10 \\% $$\n",
    "$$ P ( S ) = 1 - P ( F ) = 85\\% $$\n",
    "\n",
    "So that we have \n",
    "\n",
    "$$ P ( - ) = P ( - | F ) * P ( F ) + P ( - | S ) * P ( S ) $$\n",
    "$$ = 0.95 * 0.15 + 0.10 * 0.85 $$\n",
    "$$ = 0.2275 $$\n",
    "\n",
    "and \n",
    "\n",
    "$$ P ( F | - ) = \\frac{ P ( - | F ) P ( F ) }{ P ( - ) } $$\n",
    "$$ = \\frac{ 0.95 * 0.15 }{ 0.2275 } $$\n",
    "$$ = 0.6264 $$ \n",
    "\n",
    "$$ P ( S | - )  = \\frac{ P ( - | S ) P ( S ) }{ P ( - ) } $$\n",
    "$$ = \\frac { 0.10 * 0.85 } { 0.2275 } $$\n",
    "$$ = 0.3736 $$\n",
    "\n",
    "Thus, under the circumstance that the model predicts fail, the hedge has a probability of 0.6264 to fail and a probability of 0.3736 to success. \n",
    "\n",
    "Assume we have initial wealth $w$, $10\\%w$ in hedge fund and $90\\%w$ in cash.\n",
    "\n",
    "If money stays in the hedge fund, the expected utility will be \n",
    "\n",
    "$$ E[u(w)]_{stay} = P ( F | - ) * \\ln{( 0.1w * 0.5 + 0.9w )} + P ( S | - ) * \\ln{( 0.1w * 1.85 + 0.9w )} $$ \n",
    "$$ = 0.6264 * \\ln{ 0.95w } + 0.3736 * \\ln{ 1.085w } $$\n",
    "$$ = 0.6264 * \\ln{ 0.95 } + 0.3736 * \\ln{ 1.085 } + 0.6264\\ln{w} + 0.3736\\ln{w}$$\n",
    "$$ = \\ln{ w } - 0.0016518 $$\n",
    "\n",
    "If we pull out the money, the expected utility will be \n",
    "$$ E[u(w)]_{out} = \\ln{( 0.1w * 0.98 + 0.9w )} $$\n",
    "$$ = \\ln { 0.998w } $$\n",
    "$$ = \\ln { 0.998 } + \\ln{ w } $$\n",
    "$$ = \\ln{ w }  - 0.002002 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, $ \\text{for all } w > 0, \\text{ we have } E[u(w)]_{stay} > E[u(w)]_{out}$ . \n",
    "\n",
    "We should stay the money with the hedge fund. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> Personal validation for Q3, no need to run.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_utility_stay(w):\n",
    "    \"\"\"\n",
    "    Calculate the expected utility if stay with hedge fund given initial wealth\n",
    "    \"\"\"\n",
    "    return 0.6264 * np.log(0.95 * w) + 0.3736 * np.log(1.085 * w) \n",
    "\n",
    "def expected_utility_out(w):\n",
    "    \"\"\"\n",
    "    Calculate the expected utility if we take 10% money out and stay in cash \n",
    "    \"\"\"\n",
    "    return np.log(0.998 * w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.linspace(1, 1000000, 1000) # initial wealth \n",
    "\n",
    "# final expected utilities given different initial wealth \n",
    "expUtilStay = [expected_utility_stay(w) for w in w0]\n",
    "expUtilOut = [expected_utility_out(w) for w in w0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11bd89518>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot \n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "plt.plot(w0, expUtilStay, '-g', label='Stay')\n",
    "plt.plot(w0, expUtilOut, ':b', label='Out')\n",
    "plt.ylabel(\"Utility\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From WolframAlpha, we always have expected_utility_stay > expected_utility_out . Should stay with the hedge fund."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
