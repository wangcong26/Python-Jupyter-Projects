{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import qrbook_funcs as qf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "import scipy.stats as spst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1 Prove that the vector x_sol=(1, 1/2, −1) is the optimal solution to the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=np.array([[0.5194, 0.2494, 0.2207], [0.2494, 0.3568, 0.1166], [0.2207, 0.1166, 0.4155]])\n",
    "m=np.array([1.4234, 0.3112, -1.1365]).reshape(3,1)\n",
    "Xsol=np.array([1,0.5,-1]).reshape(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00000000e+00],\n",
       "       [ 5.55111512e-17],\n",
       "       [ 1.00000000e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the Gradient of f(x), which is used in my handwriting answer sheet\n",
    "gradient_f=np.matmul(C,Xsol)-m\n",
    "gradient_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3 Compute the Box M test statistic M(1,2) given in (4.52), where S1 is the example 3x3 currency covariance matrix we’ve been using (Swissie, pound, yen up to the end of last year), and S2 is the 3x3 sample currency covariance matrix arising from the Monte Carlo simulation in Chapter 7 (which can be obtained from np.cov(r_trial.T) after the code following (7.12)). Apply Levene’s test (section 4.2.2.2) to the three variances. Can we accept the hypothesis that they are the same? Apply the Box M test as described in section 4.2.2.3 to the two covariance matrices. Can we accept the hypothesis that the two matrices are the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get 3 currencies until the end of previous year. \n",
    "lastday=qf.LastYearEnd()\n",
    "#Swiss franc, pound sterling, Japanese Yen\n",
    "seriesnames=['DEXSZUS','DEXUSUK','DEXJPUS']\n",
    "cdates,ratematrix=qf.GetFREDMatrix(seriesnames,enddate=lastday)\n",
    "\n",
    "#Convert levels to log-returns\n",
    "#First take logs of the currency levels\n",
    "#Currency exchange rates are usually expressed in the direction\n",
    "#that will make the rate > 1\n",
    "#Swissie and yen are in currency/dollar, but\n",
    "#pounds is in dollar/currency. Reverse signs\n",
    "#so everything is in dollar/currency\n",
    "\n",
    "#Do each currency separately to account for separate missing data patterns\n",
    "#dlgs is a list of lists of length 3 corresponding to the 3 currencies\n",
    "#The value in dlgs is nan if there is missing data for the present or previous day's observation\n",
    "#Otherwise it is the log of today/yesterday\n",
    "multipliers=[-1,1,-1]\n",
    "dlgs=[]\n",
    "for i in range(len(multipliers)):\n",
    "    lgrates=[]\n",
    "    previous=-1\n",
    "    for t in range(len(ratematrix)):\n",
    "        if pd.isna(ratematrix[t][i]) or ratematrix[t][i]<=0:\n",
    "            lgrates.append(np.nan)    #Append a nan\n",
    "        else:\n",
    "            if previous < 0:    #This is the first data point\n",
    "                lgrates.append(np.nan)\n",
    "            else:\n",
    "                lgrates.append(np.log(ratematrix[t][i]/previous)*multipliers[i])\n",
    "            previous=ratematrix[t][i]\n",
    "    dlgs.append(lgrates)\n",
    "\n",
    "#dlgs is the transpose of what we want - flip it\n",
    "dlgs=np.transpose(dlgs)\n",
    "\n",
    "#Delete any time periods that don't have data\n",
    "lgdates=[]\n",
    "difflgs=[]\n",
    "for t in range(len(dlgs)):\n",
    "    if all(pd.notna(dlgs[t])):\n",
    "        #include this time period\n",
    "        difflgs.append(dlgs[t])\n",
    "        lgdates.append(cdates[t])\n",
    "\n",
    "#Mean vector and covariance matrix are inputs to efficient frontier calculations\n",
    "d=np.array(difflgs)\n",
    "m=np.mean(d,axis=0)\n",
    "c=np.cov(d.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════╤═══════════════╕\n",
      "│ Statistic          │         Value │\n",
      "╞════════════════════╪═══════════════╡\n",
      "│ Count              │ 12036         │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Min                │    -0.0203071 │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Max                │     0.0214615 │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Mean               │     6.65e-05  │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Median             │     8.36e-05  │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Standard Deviation │     0.0052779 │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Skewness           │     0.0010422 │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Excess Kurtosis    │     0.0373164 │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Jarque-Bera        │     0.700526  │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Chi-Squared p      │     0.704503  │\n",
      "├────────────────────┼───────────────┤\n",
      "│ Serial Correlation │     0.0013274 │\n",
      "├────────────────────┼───────────────┤\n",
      "│ 99% VaR            │     0.0120789 │\n",
      "├────────────────────┼───────────────┤\n",
      "│ 99% cVaR           │     0.0140765 │\n",
      "╘════════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "#Generate random draws; use fixed seed to be replicable\n",
    "count=12036 \n",
    "\n",
    "#Show the Cholesky decomposition of the CHF-GPB-JPY covariance matrix\n",
    "chol=np.linalg.cholesky(c)\n",
    "\n",
    "seed=np.random.seed(12345678)\n",
    "s_trial=np.random.normal(0,1,size=[int(count),3])\n",
    "logr_trial=np.matmul(chol,s_trial.T).T+m\n",
    "\n",
    "#logr_trial has Monte Carlo log-returns; transform to returns\n",
    "r_trial=np.exp(logr_trial)-1\n",
    "\n",
    "#CHF-GBP-JPY \n",
    "w=np.array([1/3]*3).T\n",
    "\n",
    "#Get trial portfolio returns\n",
    "r_ptrial=np.matmul(r_trial,w)\n",
    "statnames,mettrial,tabtrial=qf.StatsTable(r_ptrial)\n",
    "headers=['Statistic','Value']\n",
    "print(tabulate(tabtrial, headers, tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00411198, -0.01075888,  0.00358579, ..., -0.00592292,\n",
       "       -0.00307315,  0.00125228])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first column\n",
    "r_trial[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12036, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1 is the covariance matrix using the data up to last year\n",
    "S1=c*10000\n",
    "# S2 is from the simulation above\n",
    "S2=np.cov(r_trial.T) * 10000\n",
    "\n",
    "# T1 is the sample size\n",
    "T1=len(lgdates)\n",
    "# T2 is the sample size\n",
    "T2=count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.51941274, 0.24943128, 0.22066643],\n",
       "        [0.24943128, 0.35676267, 0.11657374],\n",
       "        [0.22066643, 0.11657374, 0.41545275]]),\n",
       " array([[0.52151159, 0.25497548, 0.22517401],\n",
       "        [0.25497548, 0.36411532, 0.12335733],\n",
       "        [0.22517401, 0.12335733, 0.41460933]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1, S2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Below is the Levene's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene statistic for DEXSZUS:  127.20267337053697 , p-value:  1.1102230246251565e-16\n",
      "Reject null hypothesis of equal variances at 99% significance\n",
      "Levene statistic for DEXUSUK:  166.24256039528214 , p-value:  1.1102230246251565e-16\n",
      "Reject null hypothesis of equal variances at 99% significance\n",
      "Levene statistic for DEXJPUS:  177.52316917940098 , p-value:  1.1102230246251565e-16\n",
      "Reject null hypothesis of equal variances at 99% significance\n"
     ]
    }
   ],
   "source": [
    "# Apply Levene's Test to three-currency example with previous years compared to latest year\n",
    "#Note the results shown are the same as\n",
    "#scipy.stats.levene(d[:prev_year_n,k],d[prev_year_n:,k],center='mean')\n",
    "\n",
    "# threshold is 1%\n",
    "thresh=.01\n",
    "one_minus_thresh=(1-thresh)*100\n",
    "\n",
    "def levene(T1,T2,x1,x2):\n",
    "\n",
    "    m1=np.average(x1)\n",
    "    m2=np.average(x2)\n",
    "    z1j=[np.abs(x1[j]-m1) for j in range(T1)]\n",
    "    z2j=[np.abs(x2[j]-m2) for j in range(T2)]\n",
    "    z1=np.average(z1j)\n",
    "    z2=np.average(z2j)\n",
    "\n",
    "    levene_mult=(T1+T2-2)*T1*T2/(T1+T2)\n",
    "\n",
    "    levene_denom=np.sum((z1j-z1)**2)+np.sum((z2j-z2)**2)\n",
    "    levene_stat=levene_mult*(z1-z2)**2/levene_denom\n",
    "\n",
    "    p_value = 1 - spst.f.cdf(levene_stat, 1, T1+T2-2)\n",
    "\n",
    "    return(levene_stat,p_value)\n",
    "\n",
    "for i in range(3):\n",
    "    lstat, p_value = levene(T1,T2,d[:,i],r_trial[:,i])\n",
    "    print(\"Levene statistic for \"+seriesnames[i]+\": \",lstat,\", p-value: \",p_value)\n",
    "    if p_value < thresh:\n",
    "        str_p=\"Reject null hypothesis of equal variances at %2.f\" % one_minus_thresh\n",
    "    else:\n",
    "        str_p=\"Cannot reject null hypothesis of equal variances at %2.f\" % one_minus_thresh\n",
    "    str_p+=\"% significance\"\n",
    "    print(str_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Below is the Box test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoxM(T1,T2,s1,s2):\n",
    "    #Tests for equality of two covariance matrices, s1 and s2\n",
    "    #T1 and T2 are numbers of observations for s1 and s2\n",
    "    #Returns M statistic and p-value\n",
    "\n",
    "    #Make sure dimension is common\n",
    "    if len(s1)!=len(s2):\n",
    "        print(\"Error: different dimensions in Box M Test:\",len(s1),len(s2))\n",
    "        return(0,0)\n",
    "    \n",
    "    #Matrices are pxp\n",
    "    p=len(s1)\n",
    "\n",
    "    #Form the combined matrix\n",
    "    scomb=(T1*s1+T2*s2)/(T1+T2)\n",
    "\n",
    "    #Box M statistic\n",
    "    Mstat=(T1+T2-2)*np.log(np.linalg.det(scomb))-(T1-1)*np.log(np.linalg.det(s1))-(T2-1)*np.log(np.linalg.det(s2))\n",
    "\n",
    "    #Multipliers from equation (49) in Box 1949.\n",
    "    A1=(2*p**2+3*p-1)/(6*(p+1))\n",
    "    A1*=(1/(T1-1)+1/(T2-1)-1/(T1+T2-2))\n",
    "\n",
    "    A2=(p-1)*(p+2)/6\n",
    "    A2*=(1/(T1-1)**2+1/(T2-1)**2-1/(T1+T2-2)**2)\n",
    "\n",
    "    discrim=A2-A1**2\n",
    "\n",
    "    #Degrees of freedom\n",
    "    df1=p*(p+1)/2\n",
    "\n",
    "    if discrim <= 0:\n",
    "        #Use chi-square (Box 1949 top p. 329)\n",
    "        test_value=Mstat*(1-A1)\n",
    "        p_value=1-spst.chi2.cdf(test_value,df1)\n",
    "    else:\n",
    "        #Use F Test (Box 1949 equation (68))\n",
    "        df2=(df1+2)/discrim\n",
    "        b=df1/(1-A1-(df1/df2))\n",
    "        test_value=Mstat/b\n",
    "        p_value=1-spst.f.cdf(test_value,df1,df2)\n",
    "    \n",
    "    return(test_value,p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box M-stat and p-value is: 0.48531478642713505 0.8198217436021252\n",
      "Cannot reject null hypothesis of equal variances at 99% significance\n"
     ]
    }
   ],
   "source": [
    "#Apply to sample variances\n",
    "stat, p_value = BoxM(T1,T2,S1,S2)\n",
    "print(\"Box M-stat and p-value is:\",stat,p_value)\n",
    "\n",
    "\n",
    "if p_value < thresh:\n",
    "    str_p=\"Reject null hypothesis of equal variances at %2.f\" % one_minus_thresh\n",
    "else:\n",
    "    str_p=\"Cannot reject null hypothesis of equal variances at %2.f\" % one_minus_thresh\n",
    "str_p+=\"% significance\"\n",
    "print(str_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
